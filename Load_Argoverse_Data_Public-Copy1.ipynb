{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "test_path = './new_val_in/new_val_in'\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "test_dataset = ArgoverseDataset(data_path=test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def train_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "# #     inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "#     inp = [numpy.dstack([scene['p_in']]) for scene in batch]\n",
    "# #     out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "#     out = [numpy.dstack([scene['p_out']]) for scene in batch]\n",
    "    inp = [numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:], scene['v_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch]\n",
    "#     out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'][scene['track_id'][:,0,0]==scene['agent_id'],:,:], scene['v_out'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch]\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:], scene['v_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch]\n",
    "    inp = torch.Tensor(inp)\n",
    "    idx = [numpy.dstack([scene['scene_idx']]) for scene in batch]\n",
    "    return inp, idx\n",
    "    \n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=train_collate, num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"Encoder Network.\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_size: int = 2,\n",
    "                 embedding_size: int = 8,\n",
    "                 hidden_size: int = 16):\n",
    "        \"\"\"Initialize the encoder network.\n",
    "\n",
    "        Args:\n",
    "            input_size: number of features in the input\n",
    "            embedding_size: Embedding size\n",
    "            hidden_size: Hidden size of LSTM\n",
    "\n",
    "        \"\"\"\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, embedding_size)\n",
    "        self.lstm1 = nn.LSTMCell(embedding_size, hidden_size)\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor, hidden: Any) -> Any:\n",
    "        \"\"\"Run forward propagation.\n",
    "\n",
    "        Args:\n",
    "            x: input to the network\n",
    "            hidden: initial hidden state\n",
    "        Returns:\n",
    "            hidden: final hidden \n",
    "\n",
    "        \"\"\"\n",
    "        embedded = F.relu(self.linear1(x))\n",
    "        hidden = self.lstm1(embedded, hidden)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"Decoder Network.\"\"\"\n",
    "    def __init__(self, embedding_size=8, hidden_size=16, output_size=2):\n",
    "        \"\"\"Initialize the decoder network.\n",
    "\n",
    "        Args:\n",
    "            embedding_size: Embedding size\n",
    "            hidden_size: Hidden size of LSTM\n",
    "            output_size: number of features in the output\n",
    "\n",
    "        \"\"\"\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.linear1 = nn.Linear(output_size, embedding_size)\n",
    "        self.lstm1 = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"Run forward propagation.\n",
    "\n",
    "        Args:\n",
    "            x: input to the network\n",
    "            hidden: initial hidden state\n",
    "        Returns:\n",
    "            output: output from lstm\n",
    "            hidden: final hidden state\n",
    "\n",
    "        \"\"\"\n",
    "        embedded = F.relu(self.linear1(x))\n",
    "        hidden = self.lstm1(embedded, hidden)\n",
    "        output = self.linear2(hidden[0])\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def train(\n",
    "        train_loader: Any,\n",
    "        epoch: int,\n",
    "        criterion: Any,\n",
    "        logger: Logger,\n",
    "        encoder: Any,\n",
    "        decoder: Any,\n",
    "        encoder_optimizer: Any,\n",
    "        decoder_optimizer: Any,\n",
    "        model_utils: ModelUtils,\n",
    "        rollout_len: int = 30,\n",
    ") -> None:\n",
    "    \"\"\"Train the lstm network.\n",
    "\n",
    "    Args:\n",
    "        train_loader: DataLoader for the train set\n",
    "        epoch: epoch number\n",
    "        criterion: Loss criterion\n",
    "        logger: Tensorboard logger\n",
    "        encoder: Encoder network instance\n",
    "        decoder: Decoder network instance\n",
    "        encoder_optimizer: optimizer for the encoder network\n",
    "        decoder_optimizer: optimizer for the decoder network\n",
    "        model_utils: instance for ModelUtils class\n",
    "        rollout_len: current prediction horizon\n",
    "\n",
    "    \"\"\"\n",
    "    args = parse_arguments()\n",
    "    global global_step\n",
    "\n",
    "    for i, (_input, target, helpers) in enumerate(train_loader):\n",
    "        _input = _input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Set to train mode\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        # Zero the gradients\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        output_length = target.shape[1]\n",
    "        input_shape = _input.shape[2]\n",
    "\n",
    "        # Initialize encoder hidden state\n",
    "        encoder_hidden = model_utils.init_hidden(\n",
    "            batch_size,\n",
    "            encoder.module.hidden_size if use_cuda else encoder.hidden_size)\n",
    "\n",
    "        # Initialize losses\n",
    "        loss = 0\n",
    "\n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_outputs = torch.zeros(target.shape).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(rollout_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Update loss\n",
    "            loss += criterion(decoder_output[:, :2], target[:, di, :2])\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        # Get average loss for pred_len\n",
    "        loss = loss / rollout_len\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        if global_step % 1000 == 0:\n",
    "\n",
    "            # Log results\n",
    "            print(\n",
    "                f\"Train -- Epoch:{epoch}, loss:{loss}, Rollout:{rollout_len}\")\n",
    "\n",
    "            logger.scalar_summary(tag=\"Train/loss\",\n",
    "                                  value=loss.item(),\n",
    "                                  step=epoch)\n",
    "\n",
    "        global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, device, test_loader):\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    all_outs = numpy.zeros((1,60))\n",
    "    idx_out = []\n",
    "#     print(all_outs.shape)\n",
    "    with torch.no_grad():\n",
    "        for data, idx in test_loader:\n",
    "            data= data[:,0,:,:]\n",
    "            data= data.to(device)\n",
    "            output = model(data)\n",
    "            output = output[:,:,0:2].reshape(-1,60)\n",
    "            arr = output.data.cpu().numpy()\n",
    "#             print(arr.shape)\n",
    "            all_outs = numpy.append(all_outs, arr, axis=0)\n",
    "#             print(all_outs)\n",
    "#             print(idx)\n",
    "#             print('')\n",
    "            idx_out.append(int(idx[0][0][0][0]))\n",
    "            idx_out.append(int(idx[1][0][0][0]))\n",
    "            idx_out.append(int(idx[2][0][0][0]))\n",
    "            idx_out.append(int(idx[3][0][0][0]))\n",
    "#     print(all_outs.shape)\n",
    "#     print(idx_out[0])\n",
    "#     print(len(idx_out))\n",
    "    all_outs = all_outs[1:,:]\n",
    "#     all_outs = numpy.insert(all_outs, 0, idx_out, axis=1)\n",
    "#     for i in range(len(all_outs)):\n",
    "#         print(all_outs[i][0])\n",
    "#         all_outs[i][0] = idx_out[i]\n",
    "#     print(all_outs.shape)\\\n",
    "    print(all_outs)\n",
    "    return all_outs, idx_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf264657cf2841a58df713a154d240e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d551bc2f9aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#         predict(model, device, test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a5d8f675973e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(output[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         print(\"OURPUT\", output[0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-abcc9a5bd0b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#         print(x[0][:,-1,:].reshape((4,1,2)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#             print(output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 662\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model = NN().to(device) #using gpu here\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "num_epoch = 1\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, val_loader, optimizer, epoch)\n",
    "#         predict(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any, Dict, List, Tuple, Optional, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main from lstm_train_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jagjeet-singh/argoverse-forecasting/blob/master/lstm_train_test.py\n",
    "\n",
    "# $ python lstm_train_test.py \n",
    "# --train_features <path/to/train/features> \n",
    "# --val_features <path/to/val/features> \n",
    "# --test_features <path/to/test/features> \n",
    "# --model_path <path/to/saved/checkpoint> \n",
    "# --use_delta \n",
    "# --normalize \n",
    "# --obs_len 20 \n",
    "# --pred_len 30 \n",
    "# --model_path <pkl/file/path/for/model> \n",
    "# --traj_save_path <pkl/file/for/forecasted/trajectories>\n",
    "\n",
    "# training set folder path\n",
    "train_folder_path = \"./new_train/new_train\"\n",
    "\n",
    "# no validation set\n",
    "val_folder_path = None\n",
    "\n",
    "# test set folder path\n",
    "test_folder_path = './new_val_in/new_val_in'\n",
    "\n",
    "# model path (pick up from where you left off in training)\n",
    "model_path = None\n",
    "\n",
    "# model pickl (TODO: need to find out what this means)\n",
    "model_pkl = None\n",
    "\n",
    "# delta (training on change in position rather than absolute position)\n",
    "delta = True\n",
    "\n",
    "# normalize (TODO: need to find out what this means)\n",
    "normalize = True\n",
    "\n",
    "# obs_len (train on given number of steps)\n",
    "obs_len = 19\n",
    "\n",
    "# pred_len (predict number of steps)\n",
    "pred_len = 30\n",
    "\n",
    "# trajectory save path (where we save our predicted path)\n",
    "traj_path = \"./trajectory.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "# TODO match this to lstm train test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelUtils:\n",
    "    \"\"\"Utils for LSTM baselines.\"\"\"\n",
    "    def save_checkpoint(self, save_dir: str, state: Dict[str, Any]) -> None:\n",
    "        \"\"\"Save checkpoint file.\n",
    "        \n",
    "        Args:\n",
    "            save_dir: Directory where model is to be saved\n",
    "            state: State of the model\n",
    "\n",
    "        \"\"\"\n",
    "        filename = \"{}/LSTM_rollout{}.pth.tar\".format(save_dir,\n",
    "                                                      state[\"rollout_len\"])\n",
    "        torch.save(state, filename)\n",
    "\n",
    "    def load_checkpoint(\n",
    "            self,\n",
    "            checkpoint_file: str,\n",
    "            encoder: Any,\n",
    "            decoder: Any,\n",
    "            encoder_optimizer: Any,\n",
    "            decoder_optimizer: Any,\n",
    "    ) -> Tuple[int, int, float]:\n",
    "        \"\"\"Load the checkpoint.\n",
    "\n",
    "        Args:\n",
    "            checkpoint_file: Path to checkpoint file\n",
    "            encoder: Encoder model\n",
    "            decoder: Decoder model \n",
    "\n",
    "        Returns:\n",
    "            epoch: epoch when the model was saved.\n",
    "            rollout_len: horizon used\n",
    "            best_loss: loss when the checkpoint was saved\n",
    "\n",
    "        \"\"\"\n",
    "        if os.path.isfile(checkpoint_file):\n",
    "            print(\"=> loading checkpoint '{}'\".format(checkpoint_file))\n",
    "            checkpoint = torch.load(checkpoint_file)\n",
    "            epoch = checkpoint[\"epoch\"]\n",
    "            best_loss = checkpoint[\"best_loss\"]\n",
    "            rollout_len = checkpoint[\"rollout_len\"]\n",
    "            if use_cuda:\n",
    "                encoder.module.load_state_dict(\n",
    "                    checkpoint[\"encoder_state_dict\"])\n",
    "                decoder.module.load_state_dict(\n",
    "                    checkpoint[\"decoder_state_dict\"])\n",
    "            else:\n",
    "                encoder.load_state_dict(checkpoint[\"encoder_state_dict\"])\n",
    "                decoder.load_state_dict(checkpoint[\"decoder_state_dict\"])\n",
    "            encoder_optimizer.load_state_dict(checkpoint[\"encoder_optimizer\"])\n",
    "            decoder_optimizer.load_state_dict(checkpoint[\"decoder_optimizer\"])\n",
    "            print(\n",
    "                f\"=> loaded checkpoint {checkpoint_file} (epoch: {epoch}, loss: {best_loss})\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"=> no checkpoint found at {checkpoint_file}\")\n",
    "\n",
    "        return epoch, rollout_len, best_loss\n",
    "\n",
    "    def my_collate_fn(self, batch: List[Any]) -> List[Any]:\n",
    "        \"\"\"Collate function for PyTorch DataLoader.\n",
    "\n",
    "        Args:\n",
    "            batch: Batch data\n",
    "\n",
    "        Returns: \n",
    "            input, output and helpers in the format expected by DataLoader\n",
    "\n",
    "        \"\"\"\n",
    "        _input, output, helpers = [], [], []\n",
    "\n",
    "        for item in batch:\n",
    "            _input.append(item[0])\n",
    "            output.append(item[1])\n",
    "            helpers.append(item[2])\n",
    "        _input = torch.stack(_input)\n",
    "        output = torch.stack(output)\n",
    "        return [_input, output, helpers]\n",
    "\n",
    "    def init_hidden(self, batch_size: int,\n",
    "                    hidden_size: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"Get initial hidden state for LSTM.\n",
    "\n",
    "        Args:\n",
    "            batch_size: Batch size\n",
    "            hidden_size: Hidden size of LSTM\n",
    "\n",
    "        Returns:\n",
    "            Initial hidden states\n",
    "\n",
    "        \"\"\"\n",
    "        return (\n",
    "            torch.zeros(batch_size, hidden_size).to(device),\n",
    "            torch.zeros(batch_size, hidden_size).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils = ModelUtils()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(test_features, train_features) -> Dict[str, Union[np.ndarray, pd.DataFrame, None]]:\n",
    "    \"\"\"Load data from local data_dir.\n",
    "\n",
    "    Args:\n",
    "        args (argparse): Arguments to baseline\n",
    "        baseline_key: Key for obtaining features for the baseline\n",
    "    Returns:\n",
    "        data_dict (dict): Dictionary of input/output data and helpers for train/val/test splits\n",
    "\n",
    "    \"\"\"\n",
    "    input_features = [\"X\", \"Y\"]\n",
    "    output_features = [\"X\", \"Y\"]\n",
    "    if test_features:\n",
    "        print(\"Loading Test data ...\")\n",
    "        test_input, test_output, test_df = load_and_preprocess_data(\n",
    "            input_features,\n",
    "            output_features,\n",
    "            test_features,\n",
    "            mode=\"test\")\n",
    "        print(\"Test Size: {}\".format(test_input.shape[0]))\n",
    "    else:\n",
    "        test_input, test_output, test_df = [None] * 3\n",
    "\n",
    "    if train_features:\n",
    "        print(\"Loading Train data ...\")\n",
    "        train_input, train_output, train_df = load_and_preprocess_data(\n",
    "            input_features,\n",
    "            output_features,\n",
    "            args,\n",
    "            args.train_features,\n",
    "            mode=\"train\")\n",
    "        print(\"Train Size: {}\".format(train_input.shape[0]))\n",
    "    else:\n",
    "        train_input, train_output, train_df = [None] * 3\n",
    "\n",
    "    data_dict = {\n",
    "        \"train_input\": train_input,\n",
    "        \"test_input\": test_input,\n",
    "        \"train_output\": train_output,\n",
    "        \"test_output\": test_output,\n",
    "        \"train_helpers\": train_df,\n",
    "        \"test_helpers\": test_df,\n",
    "    }\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(\n",
    "        input_features: List[str],\n",
    "        output_features: List[str],\n",
    "        feature_file: str,\n",
    "        mode: str = \"train\",\n",
    ") -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"Load the data and preprocess based on given arguments.\n",
    "\n",
    "    Args:\n",
    "        input_features (list of str): Input features for the baseline\n",
    "        output_features (list of str): Output features for the baseline\n",
    "        args (argparse): Arguments to runNNBaselines.py/runLSTMBaselines.py\n",
    "        feature_file: path to the file containing features\n",
    "        mode (str): train/val/test\n",
    "    Returns:\n",
    "        _input: Input to the baseline\n",
    "        _output: Ground truth \n",
    "        df: Helper values useful in visualization and evaluation\n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.read_pickle(feature_file)\n",
    "\n",
    "    # Normalize if its a non-map baseline\n",
    "    if not args.use_map and args.normalize:\n",
    "\n",
    "        print(\"Normalizing ...\")\n",
    "\n",
    "        # Don't use X,Y as features\n",
    "        input_feature_idx = [\n",
    "            FEATURE_FORMAT[feature] for feature in input_features\n",
    "            if feature != \"X\" and feature != \"Y\"\n",
    "        ]\n",
    "        output_feature_idx = [\n",
    "            FEATURE_FORMAT[feature] for feature in output_features\n",
    "            if feature != \"X\" and feature != \"Y\"\n",
    "        ]\n",
    "\n",
    "        # Normalize the trajectory\n",
    "        normalized_traj_arr = get_normalized_traj(df, args)\n",
    "\n",
    "        # Get other features\n",
    "        input_features_data = np.stack(\n",
    "            df[\"FEATURES\"].values)[:, :, input_feature_idx].astype(\"float\")\n",
    "        output_features_data = np.stack(\n",
    "            df[\"FEATURES\"].values)[:, :, output_feature_idx].astype(\"float\")\n",
    "\n",
    "        # Merge normalized trajectory and other features\n",
    "        input_features_data = np.concatenate(\n",
    "            (normalized_traj_arr, input_features_data), axis=2)\n",
    "        output_features_data = np.concatenate(\n",
    "            (normalized_traj_arr, output_features_data), axis=2)\n",
    "\n",
    "    else:\n",
    "\n",
    "        input_feature_idx = [\n",
    "            FEATURE_FORMAT[feature] for feature in input_features\n",
    "        ]\n",
    "        output_feature_idx = [\n",
    "            FEATURE_FORMAT[feature] for feature in output_features\n",
    "        ]\n",
    "\n",
    "        input_features_data = np.stack(\n",
    "            df[\"FEATURES\"].values)[:, :, input_feature_idx].astype(\"float\")\n",
    "        output_features_data = np.stack(\n",
    "            df[\"FEATURES\"].values)[:, :, output_feature_idx].astype(\"float\")\n",
    "\n",
    "    # If using relative distance instead of absolute\n",
    "    # Store the first coordinate (reference) of the trajectory to map it back to absolute values later\n",
    "    if args.use_delta:\n",
    "\n",
    "        # Get relative distances for all topk centerline candidates\n",
    "        if args.use_map and mode == \"test\":\n",
    "\n",
    "            print(\"Creating relative distances for candidate centerlines...\")\n",
    "\n",
    "            # Relative candidate distances nt\n",
    "            candidate_nt_distances = df[\"CANDIDATE_NT_DISTANCES\"].values\n",
    "            candidate_references = []\n",
    "            for candidate_nt_dist_i in candidate_nt_distances:\n",
    "                curr_reference = []\n",
    "                for curr_candidate_nt in candidate_nt_dist_i:\n",
    "                    curr_candidate_reference = get_relative_distance(\n",
    "                        np.expand_dims(curr_candidate_nt, 0), mode, args)\n",
    "                    curr_candidate_nt = curr_candidate_nt.squeeze()\n",
    "                    curr_reference.append(curr_candidate_reference.squeeze())\n",
    "                candidate_references.append(curr_reference)\n",
    "\n",
    "            df[\"CANDIDATE_DELTA_REFERENCES\"] = candidate_references\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"Creating relative distances...\")\n",
    "\n",
    "            # Relative features\n",
    "            reference = get_relative_distance(input_features_data, mode, args)\n",
    "            _ = get_relative_distance(output_features_data, mode, args)\n",
    "            df[\"DELTA_REFERENCE\"] = reference.tolist()\n",
    "\n",
    "    # Set train and test input/output data\n",
    "    _input = input_features_data[:, :args.obs_len]\n",
    "\n",
    "    if mode == \"test\":\n",
    "        _output = None\n",
    "    else:\n",
    "        _output = output_features_data[:, args.obs_len:]\n",
    "\n",
    "    return _input, _output, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e80b697d78aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-dbca6a7ee328>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moutput_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading Test data ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         test_input, test_output, test_df = load_and_preprocess_data(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "data_dict = get_data(\n",
    "    test_features = test_folder_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
