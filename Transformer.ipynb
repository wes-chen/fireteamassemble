{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy\n",
    "import pickle\n",
    "from glob import glob\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "test_path = './new_val_in/new_val_in'\n",
    "subset_test_path = './new_train/train_subset'\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu111\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "test_dataset = ArgoverseDataset(data_path=test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = numpy.array([val_dataset[0],val_dataset[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = numpy.concatenate([numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "inp = torch.Tensor(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3235.39526367, 1929.49365234],\n",
       "        [3235.85620117, 1929.80456543],\n",
       "        [3235.94506836, 1929.90905762],\n",
       "        [3237.28198242, 1931.51367188],\n",
       "        [3237.79418945, 1931.74328613],\n",
       "        [3238.26123047, 1932.32592773],\n",
       "        [3238.71533203, 1932.63842773],\n",
       "        [3239.05664062, 1932.74816895],\n",
       "        [3239.63549805, 1933.54748535],\n",
       "        [3240.15014648, 1934.04931641],\n",
       "        [3240.55395508, 1934.35949707],\n",
       "        [3241.04003906, 1934.9621582 ],\n",
       "        [3241.54272461, 1935.44311523],\n",
       "        [3242.02246094, 1935.65124512],\n",
       "        [3242.36499023, 1935.9407959 ],\n",
       "        [3242.83886719, 1936.31408691],\n",
       "        [3243.12109375, 1936.5065918 ],\n",
       "        [3243.38110352, 1936.68774414],\n",
       "        [3243.88574219, 1937.12597656]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene = batch[0]\n",
    "scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['00000000-0000-0000-0000-000000000000'],\n",
       "        ['00000000-0000-0000-0000-000000000000'],\n",
       "        ['00000000-0000-0000-0000-000000000000'],\n",
       "        ...,\n",
       "        ['00000000-0000-0000-0000-000000000000'],\n",
       "        ['00000000-0000-0000-0000-000000000000'],\n",
       "        ['00000000-0000-0000-0000-000000000000']],\n",
       "\n",
       "       [['00000000-0000-0000-0000-000000000007'],\n",
       "        ['00000000-0000-0000-0000-000000000007'],\n",
       "        ['00000000-0000-0000-0000-000000000007'],\n",
       "        ...,\n",
       "        ['00000000-0000-0000-0000-000000000007'],\n",
       "        ['00000000-0000-0000-0000-000000000007'],\n",
       "        ['00000000-0000-0000-0000-000000000007']],\n",
       "\n",
       "       [['00000000-0000-0000-0000-000000000009'],\n",
       "        ['00000000-0000-0000-0000-000000000009'],\n",
       "        ['00000000-0000-0000-0000-000000000009'],\n",
       "        ...,\n",
       "        ['00000000-0000-0000-0000-000000000009'],\n",
       "        ['00000000-0000-0000-0000-000000000009'],\n",
       "        ['00000000-0000-0000-0000-000000000009']],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [['dummy51'],\n",
       "        ['dummy51'],\n",
       "        ['dummy51'],\n",
       "        ...,\n",
       "        ['dummy51'],\n",
       "        ['dummy51'],\n",
       "        ['dummy51']],\n",
       "\n",
       "       [['dummy52'],\n",
       "        ['dummy52'],\n",
       "        ['dummy52'],\n",
       "        ...,\n",
       "        ['dummy52'],\n",
       "        ['dummy52'],\n",
       "        ['dummy52']],\n",
       "\n",
       "       [['dummy53'],\n",
       "        ['dummy53'],\n",
       "        ['dummy53'],\n",
       "        ...,\n",
       "        ['dummy53'],\n",
       "        ['dummy53'],\n",
       "        ['dummy53']]], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]['track_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = numpy.array(numpy.zeros((seq_len,batch_size)))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 19\n",
    "feat_len = 2\n",
    "p = numpy.array(numpy.zeros((seq_len,batch_size, feat_len)))\n",
    "for i,scene in enumerate(batch):\n",
    "    for j in range(seq_len):\n",
    "        p[j,i,:] = scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def train_agents_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ seq_len x batch_sz x feature] \"\"\"\n",
    "    batch_size = batch_sz\n",
    "    inp_seq_len = batch[0]['p_in'][0].shape[0]\n",
    "    out_seq_len = batch[0]['p_out'][0].shape[0]\n",
    "    feat_len = 2\n",
    "    inp = numpy.array(numpy.zeros((inp_seq_len,batch_size, feat_len)))\n",
    "    out\n",
    "    for i,scene in enumerate(batch):\n",
    "        for j in range(inp_seq_len):\n",
    "            inp[j,i,:] = scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],j]\n",
    "        for j  in range(out_seq_len):\n",
    "            out[j,i,:] = scene['p_out'][scene['track_id'][:,0,0]==scene['agent_id'],j]\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def train_all_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][['dummy' not in word for word in scene['track_id'][:,0,0]],:,:]]) for scene in batch])\n",
    "    out = numpy.concatenate([numpy.dstack([scene['p_out'][['dummy' not in word for word in scene['track_id'][:,0,0]],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "    \n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    idx = [numpy.dstack([scene['scene_idx']]) for scene in batch]\n",
    "    return inp, idx\n",
    "    \n",
    "train_agent_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_agents_collate, num_workers=0)\n",
    "\n",
    "train_all_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_all_collate, num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz, shuffle = True, collate_fn=test_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# class Transformer(nn.Module): \n",
    "#     def __init__(self):\n",
    "        \n",
    "#         super(Transformer, self).__init__()\n",
    "        \n",
    "#         self.transformer = nn.Transformer(d_model=2,\n",
    "#                                          batch_first = True)\n",
    "\n",
    "#     def forward(self, x, hidden):\n",
    "#         embedded = F.relu(self.linear(x))\n",
    "#         hidden = self.lstm(embedded, hidden)\n",
    "#         return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):    \n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    \n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        \n",
    "        inp, out = sample_batch\n",
    "#         print(inp.shape)\n",
    "        # preprocessing more ????\n",
    "#         inp = inp[:,0,:,:]\n",
    "#         out = out[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(inp.shape[0]):\n",
    "            x_offset.append(inp[i][0][0].detach().clone())\n",
    "            y_offset.append(inp[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(inp.shape[0]):\n",
    "            for i in range(inp.shape[1]):\n",
    "                inp[j][i][0] = inp[j][i][0] - x_offset[j]\n",
    "                inp[j][i][1] = inp[j][i][1] - y_offset[j]\n",
    "\n",
    "        #output whatever\n",
    "        for j in range(out.shape[0]):\n",
    "            for i in range(out.shape[1]):\n",
    "                out[j][i][0] = out[j][i][0] - x_offset[j]\n",
    "                out[j][i][1] = out[j][i][1] - y_offset[j]\n",
    "        \n",
    "        _input, target = inp.to(device), out.to(device)\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #encoder \n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        output_length = target.shape[1]\n",
    "        feature_len = _input.shape[2]\n",
    "        input_shape = _input.shape[2]\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        out = model(_input, target)\n",
    "\n",
    "        \n",
    "        loss += torch.sqrt(criterion(out[:, :2], target[:, di, :2]))\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         file1 = open(\"loss_steps.txt\", \"a\")  # append mode\n",
    "#         file1.write(str(loss.item()) + \",\")\n",
    "#         file1.close()\n",
    "        \n",
    "#       output = model(data)\n",
    "#         loss = MSELoss(output, target)\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb89bc0d59b4e68813d56d74cab46ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "the batch number of src and tgt must be equal",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c24561cfeb46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_agent_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#         train(encoder, decoder, device, train_agent_loader, encoder_optimizer, decoder_optimizer, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#         predict(model, device, test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9169d4fff2e9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the batch number of src and tgt must be equal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: the batch number of src and tgt must be equal"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "transformer = nn.Transformer(d_model=2, nhead=2)\n",
    "# encoder = EncoderRNN(input_size=2)\n",
    "# decoder = DecoderRNN(output_size=2)\n",
    "\n",
    "# encoder = nn.DataParallel(encoder)\n",
    "# decoder = nn.DataParallel(decoder)\n",
    "\n",
    "# encoder.to(device)\n",
    "# decoder.to(device)\n",
    "\n",
    "# encoder_optimizer = torch.optim.Adam(encoder.parameters())\n",
    "# decoder_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters())\n",
    "\n",
    "num_epoch = 1\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    train(transformer, device, train_agent_loader, optimizer, epoch)\n",
    "#         train(encoder, decoder, device, train_agent_loader, encoder_optimizer, decoder_optimizer, epoch)\n",
    "#         predict(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_absolute(\n",
    "        test_loader: torch.utils.data.DataLoader,\n",
    "        encoder: EncoderRNN,\n",
    "        decoder: DecoderRNN,\n",
    "#         start_idx: int,\n",
    "#         forecasted_save_dir: str,\n",
    "#         model_utils: ModelUtils,\n",
    "):\n",
    "    \"\"\"Infer function for non-map LSTM baselines and save the forecasted trajectories.\n",
    "    \n",
    "    referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\n",
    "    \n",
    "    Args:\n",
    "        test_loader: DataLoader for the test set\n",
    "        encoder: Encoder network instance\n",
    "        decoder: Decoder network instance\n",
    "        start_idx: start index for the current joblib batch\n",
    "        forecasted_save_dir: Directory where forecasted trajectories are to be saved\n",
    "        model_utils: ModelUtils instance\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    forecasted_trajectories = {}\n",
    "\n",
    "    for i, (_input, idx) in enumerate(test_loader):\n",
    "        \n",
    "#         _input = _input[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(_input.shape[0]):\n",
    "            x_offset.append(_input[i][0][0].detach().clone())\n",
    "            y_offset.append(_input[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(_input.shape[0]):\n",
    "            for i in range(_input.shape[1]):\n",
    "                _input[j][i][0] = _input[j][i][0] - x_offset[j]\n",
    "                _input[j][i][1] = _input[j][i][1] - y_offset[j]\n",
    "\n",
    "        _input = _input.to(device)\n",
    "\n",
    "        # Set to eval mode\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        input_shape = _input.shape[2]\n",
    "\n",
    "        # Initialize encoder hidden state\n",
    "        encoder_hidden = (torch.zeros(batch_size, encoder.module.hidden_size).to(device), \n",
    "                          torch.zeros(batch_size, encoder.module.hidden_size).to(device))\n",
    "       \n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_outputs = torch.zeros(\n",
    "            (batch_size, 30, 2)).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        for i in range(30):\n",
    "            for j in range(batch_size):\n",
    "                decoder_outputs[j,i,0] = decoder_outputs[j,i,0] + x_offset[j]\n",
    "                decoder_outputs[j,i,1] = decoder_outputs[j,i,1] + y_offset[j]\n",
    "            \n",
    "                if (idx[j][0][0][0] in forecasted_trajectories):\n",
    "                    forecasted_trajectories[idx[j][0][0][0]].append(decoder_outputs[j,i,:].tolist())\n",
    "                else:\n",
    "                    forecasted_trajectories[idx[j][0][0][0]] = [decoder_outputs[j,i,:].tolist()]\n",
    "                \n",
    "    return(forecasted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = infer_absolute(test_loader, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(output, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    df[['v{}'.format((i*2)+1), 'v{}'.format((i*2)+2)]] = pd.DataFrame(df.get(i).tolist(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dropped_cols = list(np.arange(30))\n",
    "df2 = df.drop(dropped_cols, axis=1)\n",
    "df2.index.name = 'ID'\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"outputs6epb4all.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
