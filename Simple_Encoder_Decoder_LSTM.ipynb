{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy\n",
    "import pickle\n",
    "from glob import glob\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "test_path = './new_val_in/new_val_in'\n",
    "subset_test_path = './new_train/train_subset'\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "test_dataset = ArgoverseDataset(data_path=test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def train_agents_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    out = numpy.concatenate([numpy.dstack([scene['p_out'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def train_all_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][['dummy' not in word for word in scene['track_id'][:,0,0]],:,:]]) for scene in batch])\n",
    "    out = numpy.concatenate([numpy.dstack([scene['p_out'][['dummy' not in word for word in scene['track_id'][:,0,0]],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "    \n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    idx = [numpy.dstack([scene['scene_idx']]) for scene in batch]\n",
    "    return inp, idx\n",
    "    \n",
    "train_agent_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_agents_collate, num_workers=0)\n",
    "\n",
    "train_all_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_all_collate, num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz, shuffle = True, collate_fn=test_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size = 2,\n",
    "                 embedding_size = 8,\n",
    "                 hidden_size = 16):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        dropnum = 0.35\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.drop1 = nn.Dropout(dropnum)\n",
    "        self.drop2 = nn.BatchNorm1d(embedding_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        embedded = F.relu(self.linear(x))\n",
    "#         embedded = self.drop2(embedded)\n",
    "        hidden = self.lstm(embedded, hidden)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"Decoder Network.\"\"\"\n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    def __init__(self, embedding_size=8, hidden_size=16, output_size=2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.linear1 = nn.Linear(output_size, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = F.relu(self.linear1(x))\n",
    "        hidden = self.lstm(embedded, hidden)\n",
    "        output = self.linear2(hidden[0])\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def train(encoder, decoder, device, train_loader, encoder_optimizer, decoder_optimizer, epoch, log_interval=10000):    \n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    \n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        \n",
    "        inp, out = sample_batch\n",
    "#         print(inp.shape)\n",
    "        # preprocessing more ????\n",
    "#         inp = inp[:,0,:,:]\n",
    "#         out = out[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(inp.shape[0]):\n",
    "            x_offset.append(inp[i][0][0].detach().clone())\n",
    "            y_offset.append(inp[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(inp.shape[0]):\n",
    "            for i in range(inp.shape[1]):\n",
    "                inp[j][i][0] = inp[j][i][0] - x_offset[j]\n",
    "                inp[j][i][1] = inp[j][i][1] - y_offset[j]\n",
    "\n",
    "        #outoput whatever\n",
    "        for j in range(out.shape[0]):\n",
    "            for i in range(out.shape[1]):\n",
    "                out[j][i][0] = out[j][i][0] - x_offset[j]\n",
    "                out[j][i][1] = out[j][i][1] - y_offset[j]\n",
    "        \n",
    "        _input, target = inp.to(device), out.to(device)\n",
    "        \n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        #encoder \n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        output_length = target.shape[1]\n",
    "        feature_len = _input.shape[2]\n",
    "        input_shape = _input.shape[2]\n",
    "        \n",
    "        encoder_hidden = (torch.zeros(batch_size, encoder.module.hidden_size).to(device), \n",
    "                          torch.zeros(batch_size, encoder.module.hidden_size).to(device))\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "#         print(\"DECODER INPUT\", decoder_input.shape)\n",
    "#         print(\"DECODER HIDDEN\", decoder_hidden[0].shape)\n",
    "\n",
    "        decoder_outputs = torch.zeros(target.shape).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Update loss\n",
    "            loss += torch.sqrt(criterion(decoder_output[:, :2], target[:, di, :2]))\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        # Get average loss for pred_len\n",
    "        loss = loss / 30\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "#         file1 = open(\"loss_steps.txt\", \"a\")  # append mode\n",
    "#         file1.write(str(loss.item()) + \",\")\n",
    "#         file1.close()\n",
    "        \n",
    "#       output = model(data)\n",
    "#         loss = MSELoss(output, target)\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb29e02fa124427b62c667d346169ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "encoder = EncoderRNN(input_size=2)\n",
    "decoder = DecoderRNN(output_size=2)\n",
    "\n",
    "encoder = nn.DataParallel(encoder)\n",
    "decoder = nn.DataParallel(decoder)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "num_epoch = 1\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    train(encoder, decoder, device, train_all_loader, encoder_optimizer, decoder_optimizer, epoch)\n",
    "#         train(encoder, decoder, device, train_agent_loader, encoder_optimizer, decoder_optimizer, epoch)\n",
    "#         predict(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_absolute(\n",
    "        test_loader: torch.utils.data.DataLoader,\n",
    "        encoder: EncoderRNN,\n",
    "        decoder: DecoderRNN,\n",
    "#         start_idx: int,\n",
    "#         forecasted_save_dir: str,\n",
    "#         model_utils: ModelUtils,\n",
    "):\n",
    "    \"\"\"Infer function for non-map LSTM baselines and save the forecasted trajectories.\n",
    "    \n",
    "    referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\n",
    "    \n",
    "    Args:\n",
    "        test_loader: DataLoader for the test set\n",
    "        encoder: Encoder network instance\n",
    "        decoder: Decoder network instance\n",
    "        start_idx: start index for the current joblib batch\n",
    "        forecasted_save_dir: Directory where forecasted trajectories are to be saved\n",
    "        model_utils: ModelUtils instance\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    forecasted_trajectories = {}\n",
    "\n",
    "    for i, (_input, idx) in enumerate(test_loader):\n",
    "        \n",
    "#         _input = _input[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(_input.shape[0]):\n",
    "            x_offset.append(_input[i][0][0].detach().clone())\n",
    "            y_offset.append(_input[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(_input.shape[0]):\n",
    "            for i in range(_input.shape[1]):\n",
    "                _input[j][i][0] = _input[j][i][0] - x_offset[j]\n",
    "                _input[j][i][1] = _input[j][i][1] - y_offset[j]\n",
    "\n",
    "        _input = _input.to(device)\n",
    "\n",
    "        # Set to eval mode\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        input_shape = _input.shape[2]\n",
    "\n",
    "        # Initialize encoder hidden state\n",
    "        encoder_hidden = (torch.zeros(batch_size, encoder.module.hidden_size).to(device), \n",
    "                          torch.zeros(batch_size, encoder.module.hidden_size).to(device))\n",
    "       \n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_outputs = torch.zeros(\n",
    "            (batch_size, 30, 2)).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        for i in range(30):\n",
    "            for j in range(batch_size):\n",
    "                decoder_outputs[j,i,0] = decoder_outputs[j,i,0] + x_offset[j]\n",
    "                decoder_outputs[j,i,1] = decoder_outputs[j,i,1] + y_offset[j]\n",
    "            \n",
    "                if (idx[j][0][0][0] in forecasted_trajectories):\n",
    "                    forecasted_trajectories[idx[j][0][0][0]].append(decoder_outputs[j,i,:].tolist())\n",
    "                else:\n",
    "                    forecasted_trajectories[idx[j][0][0][0]] = [decoder_outputs[j,i,:].tolist()]\n",
    "                \n",
    "    return(forecasted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = infer_absolute(test_loader, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>39071</td>\n",
       "      <td>[577.4776000976562, 1377.28271484375]</td>\n",
       "      <td>[577.1995239257812, 1376.1295166015625]</td>\n",
       "      <td>[577.2323608398438, 1375.0042724609375]</td>\n",
       "      <td>[577.2577514648438, 1373.8751220703125]</td>\n",
       "      <td>[577.2811889648438, 1372.731689453125]</td>\n",
       "      <td>[577.298828125, 1371.5616455078125]</td>\n",
       "      <td>[577.3069458007812, 1370.3516845703125]</td>\n",
       "      <td>[577.3011474609375, 1369.08642578125]</td>\n",
       "      <td>[577.2786254882812, 1367.751708984375]</td>\n",
       "      <td>[577.2415771484375, 1366.3397216796875]</td>\n",
       "      <td>...</td>\n",
       "      <td>[577.791748046875, 1352.0955810546875]</td>\n",
       "      <td>[577.8950805664062, 1351.0784912109375]</td>\n",
       "      <td>[578.0119018554688, 1350.009521484375]</td>\n",
       "      <td>[578.1392211914062, 1348.8812255859375]</td>\n",
       "      <td>[578.267333984375, 1347.7095947265625]</td>\n",
       "      <td>[578.3826293945312, 1346.5301513671875]</td>\n",
       "      <td>[578.4727783203125, 1345.3858642578125]</td>\n",
       "      <td>[578.531982421875, 1344.3133544921875]</td>\n",
       "      <td>[578.5613403320312, 1343.3353271484375]</td>\n",
       "      <td>[578.5669555664062, 1342.460693359375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20832</td>\n",
       "      <td>[2193.87353515625, 741.1361083984375]</td>\n",
       "      <td>[2192.908447265625, 740.7027587890625]</td>\n",
       "      <td>[2192.4365234375, 740.0703125]</td>\n",
       "      <td>[2191.84716796875, 739.3858642578125]</td>\n",
       "      <td>[2191.23095703125, 738.7315063476562]</td>\n",
       "      <td>[2190.59814453125, 738.08740234375]</td>\n",
       "      <td>[2189.96044921875, 737.4569091796875]</td>\n",
       "      <td>[2189.31787109375, 736.8339233398438]</td>\n",
       "      <td>[2188.66796875, 736.211669921875]</td>\n",
       "      <td>[2188.007080078125, 735.5843505859375]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2180.66650390625, 728.9508056640625]</td>\n",
       "      <td>[2180.0361328125, 728.3533935546875]</td>\n",
       "      <td>[2179.396728515625, 727.71728515625]</td>\n",
       "      <td>[2178.740966796875, 727.0335083007812]</td>\n",
       "      <td>[2178.060546875, 726.308837890625]</td>\n",
       "      <td>[2177.353759765625, 725.5562133789062]</td>\n",
       "      <td>[2176.623779296875, 724.79345703125]</td>\n",
       "      <td>[2175.880126953125, 724.0355834960938]</td>\n",
       "      <td>[2175.137451171875, 723.291259765625]</td>\n",
       "      <td>[2174.412353515625, 722.562744140625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>[1823.029052734375, 433.646484375]</td>\n",
       "      <td>[1821.5068359375, 432.7584228515625]</td>\n",
       "      <td>[1820.4713134765625, 431.6373596191406]</td>\n",
       "      <td>[1819.4169921875, 430.7631530761719]</td>\n",
       "      <td>[1818.4356689453125, 429.9237060546875]</td>\n",
       "      <td>[1817.4482421875, 429.0968933105469]</td>\n",
       "      <td>[1816.4276123046875, 428.2197265625]</td>\n",
       "      <td>[1815.340576171875, 427.2648620605469]</td>\n",
       "      <td>[1814.182373046875, 426.2303161621094]</td>\n",
       "      <td>[1812.9744873046875, 425.15216064453125]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1801.594482421875, 414.1127014160156]</td>\n",
       "      <td>[1800.28369140625, 412.981689453125]</td>\n",
       "      <td>[1799.1533203125, 412.14300537109375]</td>\n",
       "      <td>[1798.2337646484375, 411.4197998046875]</td>\n",
       "      <td>[1797.402587890625, 410.809326171875]</td>\n",
       "      <td>[1796.6390380859375, 410.1955261230469]</td>\n",
       "      <td>[1795.910400390625, 409.5059814453125]</td>\n",
       "      <td>[1795.2052001953125, 408.6766662597656]</td>\n",
       "      <td>[1794.5181884765625, 407.67205810546875]</td>\n",
       "      <td>[1793.854248046875, 406.4963684082031]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14320</td>\n",
       "      <td>[739.6670532226562, 1376.80224609375]</td>\n",
       "      <td>[739.501220703125, 1377.0577392578125]</td>\n",
       "      <td>[739.6172485351562, 1378.027099609375]</td>\n",
       "      <td>[739.3985595703125, 1378.703125]</td>\n",
       "      <td>[739.4227294921875, 1379.5406494140625]</td>\n",
       "      <td>[739.26318359375, 1380.2574462890625]</td>\n",
       "      <td>[739.1983642578125, 1381.0107421875]</td>\n",
       "      <td>[739.0748291015625, 1381.7177734375]</td>\n",
       "      <td>[738.9851684570312, 1382.421875]</td>\n",
       "      <td>[738.888671875, 1383.1048583984375]</td>\n",
       "      <td>...</td>\n",
       "      <td>[738.3099365234375, 1390.0823974609375]</td>\n",
       "      <td>[738.2680053710938, 1390.7373046875]</td>\n",
       "      <td>[738.2235107421875, 1391.405517578125]</td>\n",
       "      <td>[738.1755981445312, 1392.0867919921875]</td>\n",
       "      <td>[738.123291015625, 1392.780029296875]</td>\n",
       "      <td>[738.06591796875, 1393.48388671875]</td>\n",
       "      <td>[738.0027465820312, 1394.19677734375]</td>\n",
       "      <td>[737.9332275390625, 1394.917236328125]</td>\n",
       "      <td>[737.8568725585938, 1395.64453125]</td>\n",
       "      <td>[737.7733764648438, 1396.378173828125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36564</td>\n",
       "      <td>[1760.8182373046875, 379.51373291015625]</td>\n",
       "      <td>[1762.6429443359375, 380.94573974609375]</td>\n",
       "      <td>[1763.9720458984375, 382.3204345703125]</td>\n",
       "      <td>[1765.2413330078125, 383.44775390625]</td>\n",
       "      <td>[1766.51123046875, 384.5288391113281]</td>\n",
       "      <td>[1767.8370361328125, 385.61279296875]</td>\n",
       "      <td>[1769.2510986328125, 386.7601623535156]</td>\n",
       "      <td>[1770.7564697265625, 388.0345764160156]</td>\n",
       "      <td>[1772.3287353515625, 389.4031677246094]</td>\n",
       "      <td>[1773.9024658203125, 390.79144287109375]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1788.010986328125, 402.9591369628906]</td>\n",
       "      <td>[1789.180419921875, 404.1715087890625]</td>\n",
       "      <td>[1790.32568359375, 405.4411315917969]</td>\n",
       "      <td>[1791.3802490234375, 406.64117431640625]</td>\n",
       "      <td>[1792.261474609375, 407.686279296875]</td>\n",
       "      <td>[1792.9158935546875, 408.5484924316406]</td>\n",
       "      <td>[1793.348876953125, 409.2332458496094]</td>\n",
       "      <td>[1793.6097412109375, 409.759765625]</td>\n",
       "      <td>[1793.7581787109375, 410.183837890625]</td>\n",
       "      <td>[1793.8377685546875, 410.5233459472656]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29056</td>\n",
       "      <td>[1755.2867431640625, 375.2449951171875]</td>\n",
       "      <td>[1756.4725341796875, 376.033203125]</td>\n",
       "      <td>[1757.2039794921875, 376.8108825683594]</td>\n",
       "      <td>[1757.9859619140625, 377.59112548828125]</td>\n",
       "      <td>[1758.7989501953125, 378.3956298828125]</td>\n",
       "      <td>[1759.637939453125, 379.1905212402344]</td>\n",
       "      <td>[1760.489501953125, 379.9773864746094]</td>\n",
       "      <td>[1761.346923828125, 380.7442626953125]</td>\n",
       "      <td>[1762.1976318359375, 381.48675537109375]</td>\n",
       "      <td>[1763.0321044921875, 382.2016296386719]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1772.3966064453125, 390.5408935546875]</td>\n",
       "      <td>[1773.2799072265625, 391.3825988769531]</td>\n",
       "      <td>[1774.1627197265625, 392.2324523925781]</td>\n",
       "      <td>[1775.0465087890625, 393.0887756347656]</td>\n",
       "      <td>[1775.9317626953125, 393.9474792480469]</td>\n",
       "      <td>[1776.817626953125, 394.80194091796875]</td>\n",
       "      <td>[1777.70263671875, 395.6438903808594]</td>\n",
       "      <td>[1778.5860595703125, 396.4646911621094]</td>\n",
       "      <td>[1779.4697265625, 397.25665283203125]</td>\n",
       "      <td>[1780.35888671875, 398.0142822265625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6181</td>\n",
       "      <td>[1713.6209716796875, 492.0508728027344]</td>\n",
       "      <td>[1713.551025390625, 492.3790283203125]</td>\n",
       "      <td>[1713.170166015625, 492.80596923828125]</td>\n",
       "      <td>[1712.977783203125, 493.2696838378906]</td>\n",
       "      <td>[1712.750732421875, 493.72381591796875]</td>\n",
       "      <td>[1712.5009765625, 494.1575622558594]</td>\n",
       "      <td>[1712.234619140625, 494.5770568847656]</td>\n",
       "      <td>[1711.938720703125, 494.9906921386719]</td>\n",
       "      <td>[1711.617919921875, 495.3985290527344]</td>\n",
       "      <td>[1711.2760009765625, 495.80059814453125]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1706.753662109375, 500.2098083496094]</td>\n",
       "      <td>[1706.3323974609375, 500.64984130859375]</td>\n",
       "      <td>[1705.92138671875, 501.10076904296875]</td>\n",
       "      <td>[1705.5235595703125, 501.56280517578125]</td>\n",
       "      <td>[1705.1414794921875, 502.0360107421875]</td>\n",
       "      <td>[1704.7769775390625, 502.5203552246094]</td>\n",
       "      <td>[1704.431884765625, 503.01580810546875]</td>\n",
       "      <td>[1704.1070556640625, 503.5222473144531]</td>\n",
       "      <td>[1703.803466796875, 504.0397033691406]</td>\n",
       "      <td>[1703.5211181640625, 504.5682373046875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>[2162.483154296875, 779.8609619140625]</td>\n",
       "      <td>[2162.492431640625, 777.8870849609375]</td>\n",
       "      <td>[2163.336669921875, 776.5493774414062]</td>\n",
       "      <td>[2164.147216796875, 775.2764282226562]</td>\n",
       "      <td>[2164.867431640625, 773.995849609375]</td>\n",
       "      <td>[2165.5048828125, 772.7185668945312]</td>\n",
       "      <td>[2166.08056640625, 771.4623413085938]</td>\n",
       "      <td>[2166.613037109375, 770.2330322265625]</td>\n",
       "      <td>[2167.114013671875, 769.0262451171875]</td>\n",
       "      <td>[2167.588623046875, 767.834228515625]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2169.380126953125, 756.7396240234375]</td>\n",
       "      <td>[2169.13525390625, 755.8766479492188]</td>\n",
       "      <td>[2168.8408203125, 755.0181274414062]</td>\n",
       "      <td>[2168.5126953125, 754.1746826171875]</td>\n",
       "      <td>[2168.16650390625, 753.3599853515625]</td>\n",
       "      <td>[2167.818115234375, 752.5872192382812]</td>\n",
       "      <td>[2167.479736328125, 751.8663330078125]</td>\n",
       "      <td>[2167.15966796875, 751.2030029296875]</td>\n",
       "      <td>[2166.863525390625, 750.5991821289062]</td>\n",
       "      <td>[2166.593505859375, 750.0538940429688]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6333</td>\n",
       "      <td>[1673.3265380859375, 295.8135681152344]</td>\n",
       "      <td>[1674.010009765625, 296.11883544921875]</td>\n",
       "      <td>[1674.1591796875, 296.41632080078125]</td>\n",
       "      <td>[1674.5501708984375, 296.7684631347656]</td>\n",
       "      <td>[1674.94287109375, 297.10504150390625]</td>\n",
       "      <td>[1675.3460693359375, 297.4331970214844]</td>\n",
       "      <td>[1675.741455078125, 297.7560729980469]</td>\n",
       "      <td>[1676.1241455078125, 298.0740051269531]</td>\n",
       "      <td>[1676.4910888671875, 298.3873291015625]</td>\n",
       "      <td>[1676.8399658203125, 298.69281005859375]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1679.52685546875, 301.0638427734375]</td>\n",
       "      <td>[1679.7691650390625, 301.2825012207031]</td>\n",
       "      <td>[1680.040283203125, 301.5308532714844]</td>\n",
       "      <td>[1680.3453369140625, 301.81231689453125]</td>\n",
       "      <td>[1680.686279296875, 302.1270751953125]</td>\n",
       "      <td>[1681.0623779296875, 302.4720764160156]</td>\n",
       "      <td>[1681.4698486328125, 302.8416442871094]</td>\n",
       "      <td>[1681.9027099609375, 303.228759765625]</td>\n",
       "      <td>[1682.3546142578125, 303.6265563964844]</td>\n",
       "      <td>[1682.819091796875, 304.02960205078125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27321</td>\n",
       "      <td>[1795.4754638671875, 411.1531066894531]</td>\n",
       "      <td>[1794.044921875, 410.4043273925781]</td>\n",
       "      <td>[1793.1468505859375, 409.3569030761719]</td>\n",
       "      <td>[1792.1912841796875, 408.536376953125]</td>\n",
       "      <td>[1791.308837890625, 407.7616882324219]</td>\n",
       "      <td>[1790.4378662109375, 407.0216064453125]</td>\n",
       "      <td>[1789.567138671875, 406.27508544921875]</td>\n",
       "      <td>[1788.66748046875, 405.49200439453125]</td>\n",
       "      <td>[1787.7210693359375, 404.64862060546875]</td>\n",
       "      <td>[1786.72314453125, 403.7373352050781]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1776.8472900390625, 394.3089294433594]</td>\n",
       "      <td>[1775.66943359375, 393.09735107421875]</td>\n",
       "      <td>[1774.3968505859375, 392.026123046875]</td>\n",
       "      <td>[1773.243408203125, 391.0588073730469]</td>\n",
       "      <td>[1772.26318359375, 390.2236633300781]</td>\n",
       "      <td>[1771.453125, 389.49786376953125]</td>\n",
       "      <td>[1770.764404296875, 388.8547058105469]</td>\n",
       "      <td>[1770.15478515625, 388.2367248535156]</td>\n",
       "      <td>[1769.586669921875, 387.5843200683594]</td>\n",
       "      <td>[1769.0328369140625, 386.83905029296875]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0   \\\n",
       "39071     [577.4776000976562, 1377.28271484375]   \n",
       "20832     [2193.87353515625, 741.1361083984375]   \n",
       "281          [1823.029052734375, 433.646484375]   \n",
       "14320     [739.6670532226562, 1376.80224609375]   \n",
       "36564  [1760.8182373046875, 379.51373291015625]   \n",
       "...                                         ...   \n",
       "29056   [1755.2867431640625, 375.2449951171875]   \n",
       "6181    [1713.6209716796875, 492.0508728027344]   \n",
       "10200    [2162.483154296875, 779.8609619140625]   \n",
       "6333    [1673.3265380859375, 295.8135681152344]   \n",
       "27321   [1795.4754638671875, 411.1531066894531]   \n",
       "\n",
       "                                             1   \\\n",
       "39071   [577.1995239257812, 1376.1295166015625]   \n",
       "20832    [2192.908447265625, 740.7027587890625]   \n",
       "281        [1821.5068359375, 432.7584228515625]   \n",
       "14320    [739.501220703125, 1377.0577392578125]   \n",
       "36564  [1762.6429443359375, 380.94573974609375]   \n",
       "...                                         ...   \n",
       "29056       [1756.4725341796875, 376.033203125]   \n",
       "6181     [1713.551025390625, 492.3790283203125]   \n",
       "10200    [2162.492431640625, 777.8870849609375]   \n",
       "6333    [1674.010009765625, 296.11883544921875]   \n",
       "27321       [1794.044921875, 410.4043273925781]   \n",
       "\n",
       "                                            2   \\\n",
       "39071  [577.2323608398438, 1375.0042724609375]   \n",
       "20832           [2192.4365234375, 740.0703125]   \n",
       "281    [1820.4713134765625, 431.6373596191406]   \n",
       "14320   [739.6172485351562, 1378.027099609375]   \n",
       "36564  [1763.9720458984375, 382.3204345703125]   \n",
       "...                                        ...   \n",
       "29056  [1757.2039794921875, 376.8108825683594]   \n",
       "6181   [1713.170166015625, 492.80596923828125]   \n",
       "10200   [2163.336669921875, 776.5493774414062]   \n",
       "6333     [1674.1591796875, 296.41632080078125]   \n",
       "27321  [1793.1468505859375, 409.3569030761719]   \n",
       "\n",
       "                                             3   \\\n",
       "39071   [577.2577514648438, 1373.8751220703125]   \n",
       "20832     [2191.84716796875, 739.3858642578125]   \n",
       "281        [1819.4169921875, 430.7631530761719]   \n",
       "14320          [739.3985595703125, 1378.703125]   \n",
       "36564     [1765.2413330078125, 383.44775390625]   \n",
       "...                                         ...   \n",
       "29056  [1757.9859619140625, 377.59112548828125]   \n",
       "6181     [1712.977783203125, 493.2696838378906]   \n",
       "10200    [2164.147216796875, 775.2764282226562]   \n",
       "6333    [1674.5501708984375, 296.7684631347656]   \n",
       "27321    [1792.1912841796875, 408.536376953125]   \n",
       "\n",
       "                                            4   \\\n",
       "39071   [577.2811889648438, 1372.731689453125]   \n",
       "20832    [2191.23095703125, 738.7315063476562]   \n",
       "281    [1818.4356689453125, 429.9237060546875]   \n",
       "14320  [739.4227294921875, 1379.5406494140625]   \n",
       "36564    [1766.51123046875, 384.5288391113281]   \n",
       "...                                        ...   \n",
       "29056  [1758.7989501953125, 378.3956298828125]   \n",
       "6181   [1712.750732421875, 493.72381591796875]   \n",
       "10200    [2164.867431640625, 773.995849609375]   \n",
       "6333    [1674.94287109375, 297.10504150390625]   \n",
       "27321   [1791.308837890625, 407.7616882324219]   \n",
       "\n",
       "                                            5   \\\n",
       "39071      [577.298828125, 1371.5616455078125]   \n",
       "20832      [2190.59814453125, 738.08740234375]   \n",
       "281       [1817.4482421875, 429.0968933105469]   \n",
       "14320    [739.26318359375, 1380.2574462890625]   \n",
       "36564    [1767.8370361328125, 385.61279296875]   \n",
       "...                                        ...   \n",
       "29056   [1759.637939453125, 379.1905212402344]   \n",
       "6181      [1712.5009765625, 494.1575622558594]   \n",
       "10200     [2165.5048828125, 772.7185668945312]   \n",
       "6333   [1675.3460693359375, 297.4331970214844]   \n",
       "27321  [1790.4378662109375, 407.0216064453125]   \n",
       "\n",
       "                                            6   \\\n",
       "39071  [577.3069458007812, 1370.3516845703125]   \n",
       "20832    [2189.96044921875, 737.4569091796875]   \n",
       "281       [1816.4276123046875, 428.2197265625]   \n",
       "14320     [739.1983642578125, 1381.0107421875]   \n",
       "36564  [1769.2510986328125, 386.7601623535156]   \n",
       "...                                        ...   \n",
       "29056   [1760.489501953125, 379.9773864746094]   \n",
       "6181    [1712.234619140625, 494.5770568847656]   \n",
       "10200    [2166.08056640625, 771.4623413085938]   \n",
       "6333    [1675.741455078125, 297.7560729980469]   \n",
       "27321  [1789.567138671875, 406.27508544921875]   \n",
       "\n",
       "                                            7   \\\n",
       "39071    [577.3011474609375, 1369.08642578125]   \n",
       "20832    [2189.31787109375, 736.8339233398438]   \n",
       "281     [1815.340576171875, 427.2648620605469]   \n",
       "14320     [739.0748291015625, 1381.7177734375]   \n",
       "36564  [1770.7564697265625, 388.0345764160156]   \n",
       "...                                        ...   \n",
       "29056   [1761.346923828125, 380.7442626953125]   \n",
       "6181    [1711.938720703125, 494.9906921386719]   \n",
       "10200   [2166.613037109375, 770.2330322265625]   \n",
       "6333   [1676.1241455078125, 298.0740051269531]   \n",
       "27321   [1788.66748046875, 405.49200439453125]   \n",
       "\n",
       "                                             8   \\\n",
       "39071    [577.2786254882812, 1367.751708984375]   \n",
       "20832         [2188.66796875, 736.211669921875]   \n",
       "281      [1814.182373046875, 426.2303161621094]   \n",
       "14320          [738.9851684570312, 1382.421875]   \n",
       "36564   [1772.3287353515625, 389.4031677246094]   \n",
       "...                                         ...   \n",
       "29056  [1762.1976318359375, 381.48675537109375]   \n",
       "6181     [1711.617919921875, 495.3985290527344]   \n",
       "10200    [2167.114013671875, 769.0262451171875]   \n",
       "6333    [1676.4910888671875, 298.3873291015625]   \n",
       "27321  [1787.7210693359375, 404.64862060546875]   \n",
       "\n",
       "                                             9   ...  \\\n",
       "39071   [577.2415771484375, 1366.3397216796875]  ...   \n",
       "20832    [2188.007080078125, 735.5843505859375]  ...   \n",
       "281    [1812.9744873046875, 425.15216064453125]  ...   \n",
       "14320       [738.888671875, 1383.1048583984375]  ...   \n",
       "36564  [1773.9024658203125, 390.79144287109375]  ...   \n",
       "...                                         ...  ...   \n",
       "29056   [1763.0321044921875, 382.2016296386719]  ...   \n",
       "6181   [1711.2760009765625, 495.80059814453125]  ...   \n",
       "10200     [2167.588623046875, 767.834228515625]  ...   \n",
       "6333   [1676.8399658203125, 298.69281005859375]  ...   \n",
       "27321     [1786.72314453125, 403.7373352050781]  ...   \n",
       "\n",
       "                                            20  \\\n",
       "39071   [577.791748046875, 1352.0955810546875]   \n",
       "20832    [2180.66650390625, 728.9508056640625]   \n",
       "281     [1801.594482421875, 414.1127014160156]   \n",
       "14320  [738.3099365234375, 1390.0823974609375]   \n",
       "36564   [1788.010986328125, 402.9591369628906]   \n",
       "...                                        ...   \n",
       "29056  [1772.3966064453125, 390.5408935546875]   \n",
       "6181    [1706.753662109375, 500.2098083496094]   \n",
       "10200   [2169.380126953125, 756.7396240234375]   \n",
       "6333     [1679.52685546875, 301.0638427734375]   \n",
       "27321  [1776.8472900390625, 394.3089294433594]   \n",
       "\n",
       "                                             21  \\\n",
       "39071   [577.8950805664062, 1351.0784912109375]   \n",
       "20832      [2180.0361328125, 728.3533935546875]   \n",
       "281        [1800.28369140625, 412.981689453125]   \n",
       "14320      [738.2680053710938, 1390.7373046875]   \n",
       "36564    [1789.180419921875, 404.1715087890625]   \n",
       "...                                         ...   \n",
       "29056   [1773.2799072265625, 391.3825988769531]   \n",
       "6181   [1706.3323974609375, 500.64984130859375]   \n",
       "10200     [2169.13525390625, 755.8766479492188]   \n",
       "6333    [1679.7691650390625, 301.2825012207031]   \n",
       "27321    [1775.66943359375, 393.09735107421875]   \n",
       "\n",
       "                                            22  \\\n",
       "39071   [578.0119018554688, 1350.009521484375]   \n",
       "20832     [2179.396728515625, 727.71728515625]   \n",
       "281      [1799.1533203125, 412.14300537109375]   \n",
       "14320   [738.2235107421875, 1391.405517578125]   \n",
       "36564    [1790.32568359375, 405.4411315917969]   \n",
       "...                                        ...   \n",
       "29056  [1774.1627197265625, 392.2324523925781]   \n",
       "6181    [1705.92138671875, 501.10076904296875]   \n",
       "10200     [2168.8408203125, 755.0181274414062]   \n",
       "6333    [1680.040283203125, 301.5308532714844]   \n",
       "27321   [1774.3968505859375, 392.026123046875]   \n",
       "\n",
       "                                             23  \\\n",
       "39071   [578.1392211914062, 1348.8812255859375]   \n",
       "20832    [2178.740966796875, 727.0335083007812]   \n",
       "281     [1798.2337646484375, 411.4197998046875]   \n",
       "14320   [738.1755981445312, 1392.0867919921875]   \n",
       "36564  [1791.3802490234375, 406.64117431640625]   \n",
       "...                                         ...   \n",
       "29056   [1775.0465087890625, 393.0887756347656]   \n",
       "6181   [1705.5235595703125, 501.56280517578125]   \n",
       "10200      [2168.5126953125, 754.1746826171875]   \n",
       "6333   [1680.3453369140625, 301.81231689453125]   \n",
       "27321    [1773.243408203125, 391.0588073730469]   \n",
       "\n",
       "                                            24  \\\n",
       "39071   [578.267333984375, 1347.7095947265625]   \n",
       "20832       [2178.060546875, 726.308837890625]   \n",
       "281      [1797.402587890625, 410.809326171875]   \n",
       "14320    [738.123291015625, 1392.780029296875]   \n",
       "36564    [1792.261474609375, 407.686279296875]   \n",
       "...                                        ...   \n",
       "29056  [1775.9317626953125, 393.9474792480469]   \n",
       "6181   [1705.1414794921875, 502.0360107421875]   \n",
       "10200    [2168.16650390625, 753.3599853515625]   \n",
       "6333    [1680.686279296875, 302.1270751953125]   \n",
       "27321    [1772.26318359375, 390.2236633300781]   \n",
       "\n",
       "                                            25  \\\n",
       "39071  [578.3826293945312, 1346.5301513671875]   \n",
       "20832   [2177.353759765625, 725.5562133789062]   \n",
       "281    [1796.6390380859375, 410.1955261230469]   \n",
       "14320      [738.06591796875, 1393.48388671875]   \n",
       "36564  [1792.9158935546875, 408.5484924316406]   \n",
       "...                                        ...   \n",
       "29056  [1776.817626953125, 394.80194091796875]   \n",
       "6181   [1704.7769775390625, 502.5203552246094]   \n",
       "10200   [2167.818115234375, 752.5872192382812]   \n",
       "6333   [1681.0623779296875, 302.4720764160156]   \n",
       "27321        [1771.453125, 389.49786376953125]   \n",
       "\n",
       "                                            26  \\\n",
       "39071  [578.4727783203125, 1345.3858642578125]   \n",
       "20832     [2176.623779296875, 724.79345703125]   \n",
       "281     [1795.910400390625, 409.5059814453125]   \n",
       "14320    [738.0027465820312, 1394.19677734375]   \n",
       "36564   [1793.348876953125, 409.2332458496094]   \n",
       "...                                        ...   \n",
       "29056    [1777.70263671875, 395.6438903808594]   \n",
       "6181   [1704.431884765625, 503.01580810546875]   \n",
       "10200   [2167.479736328125, 751.8663330078125]   \n",
       "6333   [1681.4698486328125, 302.8416442871094]   \n",
       "27321   [1770.764404296875, 388.8547058105469]   \n",
       "\n",
       "                                            27  \\\n",
       "39071   [578.531982421875, 1344.3133544921875]   \n",
       "20832   [2175.880126953125, 724.0355834960938]   \n",
       "281    [1795.2052001953125, 408.6766662597656]   \n",
       "14320   [737.9332275390625, 1394.917236328125]   \n",
       "36564      [1793.6097412109375, 409.759765625]   \n",
       "...                                        ...   \n",
       "29056  [1778.5860595703125, 396.4646911621094]   \n",
       "6181   [1704.1070556640625, 503.5222473144531]   \n",
       "10200    [2167.15966796875, 751.2030029296875]   \n",
       "6333    [1681.9027099609375, 303.228759765625]   \n",
       "27321    [1770.15478515625, 388.2367248535156]   \n",
       "\n",
       "                                             28  \\\n",
       "39071   [578.5613403320312, 1343.3353271484375]   \n",
       "20832     [2175.137451171875, 723.291259765625]   \n",
       "281    [1794.5181884765625, 407.67205810546875]   \n",
       "14320        [737.8568725585938, 1395.64453125]   \n",
       "36564    [1793.7581787109375, 410.183837890625]   \n",
       "...                                         ...   \n",
       "29056     [1779.4697265625, 397.25665283203125]   \n",
       "6181     [1703.803466796875, 504.0397033691406]   \n",
       "10200    [2166.863525390625, 750.5991821289062]   \n",
       "6333    [1682.3546142578125, 303.6265563964844]   \n",
       "27321    [1769.586669921875, 387.5843200683594]   \n",
       "\n",
       "                                             29  \n",
       "39071    [578.5669555664062, 1342.460693359375]  \n",
       "20832     [2174.412353515625, 722.562744140625]  \n",
       "281      [1793.854248046875, 406.4963684082031]  \n",
       "14320    [737.7733764648438, 1396.378173828125]  \n",
       "36564   [1793.8377685546875, 410.5233459472656]  \n",
       "...                                         ...  \n",
       "29056     [1780.35888671875, 398.0142822265625]  \n",
       "6181    [1703.5211181640625, 504.5682373046875]  \n",
       "10200    [2166.593505859375, 750.0538940429688]  \n",
       "6333    [1682.819091796875, 304.02960205078125]  \n",
       "27321  [1769.0328369140625, 386.83905029296875]  \n",
       "\n",
       "[3200 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(output, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    df[['v{}'.format((i*2)+1), 'v{}'.format((i*2)+2)]] = pd.DataFrame(df.get(i).tolist(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>39071</td>\n",
       "      <td>577.477600</td>\n",
       "      <td>1377.282715</td>\n",
       "      <td>577.199524</td>\n",
       "      <td>1376.129517</td>\n",
       "      <td>577.232361</td>\n",
       "      <td>1375.004272</td>\n",
       "      <td>577.257751</td>\n",
       "      <td>1373.875122</td>\n",
       "      <td>577.281189</td>\n",
       "      <td>1372.731689</td>\n",
       "      <td>...</td>\n",
       "      <td>578.382629</td>\n",
       "      <td>1346.530151</td>\n",
       "      <td>578.472778</td>\n",
       "      <td>1345.385864</td>\n",
       "      <td>578.531982</td>\n",
       "      <td>1344.313354</td>\n",
       "      <td>578.561340</td>\n",
       "      <td>1343.335327</td>\n",
       "      <td>578.566956</td>\n",
       "      <td>1342.460693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20832</td>\n",
       "      <td>2193.873535</td>\n",
       "      <td>741.136108</td>\n",
       "      <td>2192.908447</td>\n",
       "      <td>740.702759</td>\n",
       "      <td>2192.436523</td>\n",
       "      <td>740.070312</td>\n",
       "      <td>2191.847168</td>\n",
       "      <td>739.385864</td>\n",
       "      <td>2191.230957</td>\n",
       "      <td>738.731506</td>\n",
       "      <td>...</td>\n",
       "      <td>2177.353760</td>\n",
       "      <td>725.556213</td>\n",
       "      <td>2176.623779</td>\n",
       "      <td>724.793457</td>\n",
       "      <td>2175.880127</td>\n",
       "      <td>724.035583</td>\n",
       "      <td>2175.137451</td>\n",
       "      <td>723.291260</td>\n",
       "      <td>2174.412354</td>\n",
       "      <td>722.562744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>1823.029053</td>\n",
       "      <td>433.646484</td>\n",
       "      <td>1821.506836</td>\n",
       "      <td>432.758423</td>\n",
       "      <td>1820.471313</td>\n",
       "      <td>431.637360</td>\n",
       "      <td>1819.416992</td>\n",
       "      <td>430.763153</td>\n",
       "      <td>1818.435669</td>\n",
       "      <td>429.923706</td>\n",
       "      <td>...</td>\n",
       "      <td>1796.639038</td>\n",
       "      <td>410.195526</td>\n",
       "      <td>1795.910400</td>\n",
       "      <td>409.505981</td>\n",
       "      <td>1795.205200</td>\n",
       "      <td>408.676666</td>\n",
       "      <td>1794.518188</td>\n",
       "      <td>407.672058</td>\n",
       "      <td>1793.854248</td>\n",
       "      <td>406.496368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14320</td>\n",
       "      <td>739.667053</td>\n",
       "      <td>1376.802246</td>\n",
       "      <td>739.501221</td>\n",
       "      <td>1377.057739</td>\n",
       "      <td>739.617249</td>\n",
       "      <td>1378.027100</td>\n",
       "      <td>739.398560</td>\n",
       "      <td>1378.703125</td>\n",
       "      <td>739.422729</td>\n",
       "      <td>1379.540649</td>\n",
       "      <td>...</td>\n",
       "      <td>738.065918</td>\n",
       "      <td>1393.483887</td>\n",
       "      <td>738.002747</td>\n",
       "      <td>1394.196777</td>\n",
       "      <td>737.933228</td>\n",
       "      <td>1394.917236</td>\n",
       "      <td>737.856873</td>\n",
       "      <td>1395.644531</td>\n",
       "      <td>737.773376</td>\n",
       "      <td>1396.378174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36564</td>\n",
       "      <td>1760.818237</td>\n",
       "      <td>379.513733</td>\n",
       "      <td>1762.642944</td>\n",
       "      <td>380.945740</td>\n",
       "      <td>1763.972046</td>\n",
       "      <td>382.320435</td>\n",
       "      <td>1765.241333</td>\n",
       "      <td>383.447754</td>\n",
       "      <td>1766.511230</td>\n",
       "      <td>384.528839</td>\n",
       "      <td>...</td>\n",
       "      <td>1792.915894</td>\n",
       "      <td>408.548492</td>\n",
       "      <td>1793.348877</td>\n",
       "      <td>409.233246</td>\n",
       "      <td>1793.609741</td>\n",
       "      <td>409.759766</td>\n",
       "      <td>1793.758179</td>\n",
       "      <td>410.183838</td>\n",
       "      <td>1793.837769</td>\n",
       "      <td>410.523346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29056</td>\n",
       "      <td>1755.286743</td>\n",
       "      <td>375.244995</td>\n",
       "      <td>1756.472534</td>\n",
       "      <td>376.033203</td>\n",
       "      <td>1757.203979</td>\n",
       "      <td>376.810883</td>\n",
       "      <td>1757.985962</td>\n",
       "      <td>377.591125</td>\n",
       "      <td>1758.798950</td>\n",
       "      <td>378.395630</td>\n",
       "      <td>...</td>\n",
       "      <td>1776.817627</td>\n",
       "      <td>394.801941</td>\n",
       "      <td>1777.702637</td>\n",
       "      <td>395.643890</td>\n",
       "      <td>1778.586060</td>\n",
       "      <td>396.464691</td>\n",
       "      <td>1779.469727</td>\n",
       "      <td>397.256653</td>\n",
       "      <td>1780.358887</td>\n",
       "      <td>398.014282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6181</td>\n",
       "      <td>1713.620972</td>\n",
       "      <td>492.050873</td>\n",
       "      <td>1713.551025</td>\n",
       "      <td>492.379028</td>\n",
       "      <td>1713.170166</td>\n",
       "      <td>492.805969</td>\n",
       "      <td>1712.977783</td>\n",
       "      <td>493.269684</td>\n",
       "      <td>1712.750732</td>\n",
       "      <td>493.723816</td>\n",
       "      <td>...</td>\n",
       "      <td>1704.776978</td>\n",
       "      <td>502.520355</td>\n",
       "      <td>1704.431885</td>\n",
       "      <td>503.015808</td>\n",
       "      <td>1704.107056</td>\n",
       "      <td>503.522247</td>\n",
       "      <td>1703.803467</td>\n",
       "      <td>504.039703</td>\n",
       "      <td>1703.521118</td>\n",
       "      <td>504.568237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>2162.483154</td>\n",
       "      <td>779.860962</td>\n",
       "      <td>2162.492432</td>\n",
       "      <td>777.887085</td>\n",
       "      <td>2163.336670</td>\n",
       "      <td>776.549377</td>\n",
       "      <td>2164.147217</td>\n",
       "      <td>775.276428</td>\n",
       "      <td>2164.867432</td>\n",
       "      <td>773.995850</td>\n",
       "      <td>...</td>\n",
       "      <td>2167.818115</td>\n",
       "      <td>752.587219</td>\n",
       "      <td>2167.479736</td>\n",
       "      <td>751.866333</td>\n",
       "      <td>2167.159668</td>\n",
       "      <td>751.203003</td>\n",
       "      <td>2166.863525</td>\n",
       "      <td>750.599182</td>\n",
       "      <td>2166.593506</td>\n",
       "      <td>750.053894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6333</td>\n",
       "      <td>1673.326538</td>\n",
       "      <td>295.813568</td>\n",
       "      <td>1674.010010</td>\n",
       "      <td>296.118835</td>\n",
       "      <td>1674.159180</td>\n",
       "      <td>296.416321</td>\n",
       "      <td>1674.550171</td>\n",
       "      <td>296.768463</td>\n",
       "      <td>1674.942871</td>\n",
       "      <td>297.105042</td>\n",
       "      <td>...</td>\n",
       "      <td>1681.062378</td>\n",
       "      <td>302.472076</td>\n",
       "      <td>1681.469849</td>\n",
       "      <td>302.841644</td>\n",
       "      <td>1681.902710</td>\n",
       "      <td>303.228760</td>\n",
       "      <td>1682.354614</td>\n",
       "      <td>303.626556</td>\n",
       "      <td>1682.819092</td>\n",
       "      <td>304.029602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27321</td>\n",
       "      <td>1795.475464</td>\n",
       "      <td>411.153107</td>\n",
       "      <td>1794.044922</td>\n",
       "      <td>410.404327</td>\n",
       "      <td>1793.146851</td>\n",
       "      <td>409.356903</td>\n",
       "      <td>1792.191284</td>\n",
       "      <td>408.536377</td>\n",
       "      <td>1791.308838</td>\n",
       "      <td>407.761688</td>\n",
       "      <td>...</td>\n",
       "      <td>1771.453125</td>\n",
       "      <td>389.497864</td>\n",
       "      <td>1770.764404</td>\n",
       "      <td>388.854706</td>\n",
       "      <td>1770.154785</td>\n",
       "      <td>388.236725</td>\n",
       "      <td>1769.586670</td>\n",
       "      <td>387.584320</td>\n",
       "      <td>1769.032837</td>\n",
       "      <td>386.839050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                v1           v2           v3           v4           v5  \\\n",
       "ID                                                                       \n",
       "39071   577.477600  1377.282715   577.199524  1376.129517   577.232361   \n",
       "20832  2193.873535   741.136108  2192.908447   740.702759  2192.436523   \n",
       "281    1823.029053   433.646484  1821.506836   432.758423  1820.471313   \n",
       "14320   739.667053  1376.802246   739.501221  1377.057739   739.617249   \n",
       "36564  1760.818237   379.513733  1762.642944   380.945740  1763.972046   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29056  1755.286743   375.244995  1756.472534   376.033203  1757.203979   \n",
       "6181   1713.620972   492.050873  1713.551025   492.379028  1713.170166   \n",
       "10200  2162.483154   779.860962  2162.492432   777.887085  2163.336670   \n",
       "6333   1673.326538   295.813568  1674.010010   296.118835  1674.159180   \n",
       "27321  1795.475464   411.153107  1794.044922   410.404327  1793.146851   \n",
       "\n",
       "                v6           v7           v8           v9          v10  ...  \\\n",
       "ID                                                                      ...   \n",
       "39071  1375.004272   577.257751  1373.875122   577.281189  1372.731689  ...   \n",
       "20832   740.070312  2191.847168   739.385864  2191.230957   738.731506  ...   \n",
       "281     431.637360  1819.416992   430.763153  1818.435669   429.923706  ...   \n",
       "14320  1378.027100   739.398560  1378.703125   739.422729  1379.540649  ...   \n",
       "36564   382.320435  1765.241333   383.447754  1766.511230   384.528839  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "29056   376.810883  1757.985962   377.591125  1758.798950   378.395630  ...   \n",
       "6181    492.805969  1712.977783   493.269684  1712.750732   493.723816  ...   \n",
       "10200   776.549377  2164.147217   775.276428  2164.867432   773.995850  ...   \n",
       "6333    296.416321  1674.550171   296.768463  1674.942871   297.105042  ...   \n",
       "27321   409.356903  1792.191284   408.536377  1791.308838   407.761688  ...   \n",
       "\n",
       "               v51          v52          v53          v54          v55  \\\n",
       "ID                                                                       \n",
       "39071   578.382629  1346.530151   578.472778  1345.385864   578.531982   \n",
       "20832  2177.353760   725.556213  2176.623779   724.793457  2175.880127   \n",
       "281    1796.639038   410.195526  1795.910400   409.505981  1795.205200   \n",
       "14320   738.065918  1393.483887   738.002747  1394.196777   737.933228   \n",
       "36564  1792.915894   408.548492  1793.348877   409.233246  1793.609741   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29056  1776.817627   394.801941  1777.702637   395.643890  1778.586060   \n",
       "6181   1704.776978   502.520355  1704.431885   503.015808  1704.107056   \n",
       "10200  2167.818115   752.587219  2167.479736   751.866333  2167.159668   \n",
       "6333   1681.062378   302.472076  1681.469849   302.841644  1681.902710   \n",
       "27321  1771.453125   389.497864  1770.764404   388.854706  1770.154785   \n",
       "\n",
       "               v56          v57          v58          v59          v60  \n",
       "ID                                                                      \n",
       "39071  1344.313354   578.561340  1343.335327   578.566956  1342.460693  \n",
       "20832   724.035583  2175.137451   723.291260  2174.412354   722.562744  \n",
       "281     408.676666  1794.518188   407.672058  1793.854248   406.496368  \n",
       "14320  1394.917236   737.856873  1395.644531   737.773376  1396.378174  \n",
       "36564   409.759766  1793.758179   410.183838  1793.837769   410.523346  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "29056   396.464691  1779.469727   397.256653  1780.358887   398.014282  \n",
       "6181    503.522247  1703.803467   504.039703  1703.521118   504.568237  \n",
       "10200   751.203003  2166.863525   750.599182  2166.593506   750.053894  \n",
       "6333    303.228760  1682.354614   303.626556  1682.819092   304.029602  \n",
       "27321   388.236725  1769.586670   387.584320  1769.032837   386.839050  \n",
       "\n",
       "[3200 rows x 60 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dropped_cols = list(np.arange(30))\n",
    "df2 = df.drop(dropped_cols, axis=1)\n",
    "df2.index.name = 'ID'\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"outputs1epb100.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
