{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy\n",
    "import pickle\n",
    "from glob import glob\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "test_path = './new_val_in/new_val_in'\n",
    "subset_test_path = './new_train/train_subset'\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "test_dataset = ArgoverseDataset(data_path=test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 100\n",
    "\n",
    "def train_agents_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    out = numpy.concatenate([numpy.dstack([scene['p_out'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def train_all_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][['dummy' not in word for word in scene['track_id'][:,0,0]],:,:]]) for scene in batch])\n",
    "    out = numpy.concatenate([numpy.dstack([scene['p_out'][['dummy' not in word for word in scene['track_id'][:,0,0]],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "    \n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    idx = [numpy.dstack([scene['scene_idx']]) for scene in batch]\n",
    "    return inp, idx\n",
    "    \n",
    "train_agent_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_agents_collate, num_workers=0)\n",
    "\n",
    "train_all_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_all_collate, num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz, shuffle = True, collate_fn=test_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size = 2,\n",
    "                 embedding_size = 8,\n",
    "                 hidden_size = 16):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = F.relu(self.linear(x))\n",
    "        hidden = self.lstm(embedded, hidden)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"Decoder Network.\"\"\"\n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    def __init__(self, embedding_size=8, hidden_size=16, output_size=2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.linear1 = nn.Linear(output_size, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = F.relu(self.linear1(x))\n",
    "        hidden = self.lstm(embedded, hidden)\n",
    "        output = self.linear2(hidden[0])\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def train(encoder, decoder, device, train_loader, encoder_optimizer, decoder_optimizer, epoch, log_interval=10000):    \n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    \n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        \n",
    "        inp, out = sample_batch\n",
    "#         print(inp.shape)\n",
    "        # preprocessing more ????\n",
    "#         inp = inp[:,0,:,:]\n",
    "#         out = out[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(inp.shape[0]):\n",
    "            x_offset.append(inp[i][0][0].detach().clone())\n",
    "            y_offset.append(inp[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(inp.shape[0]):\n",
    "            for i in range(inp.shape[1]):\n",
    "                inp[j][i][0] = inp[j][i][0] - x_offset[j]\n",
    "                inp[j][i][1] = inp[j][i][1] - y_offset[j]\n",
    "\n",
    "        #outoput whatever\n",
    "        for j in range(out.shape[0]):\n",
    "            for i in range(out.shape[1]):\n",
    "                out[j][i][0] = out[j][i][0] - x_offset[j]\n",
    "                out[j][i][1] = out[j][i][1] - y_offset[j]\n",
    "        \n",
    "        _input, target = inp.to(device), out.to(device)\n",
    "        \n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        #encoder \n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        output_length = target.shape[1]\n",
    "        feature_len = _input.shape[2]\n",
    "        input_shape = _input.shape[2]\n",
    "        \n",
    "        encoder_hidden = (torch.zeros(batch_size, encoder.module.hidden_size).to(device), \n",
    "                          torch.zeros(batch_size, encoder.module.hidden_size).to(device))\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_outputs = torch.zeros(target.shape).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Update loss\n",
    "            loss += torch.sqrt(criterion(decoder_output[:, :2], target[:, di, :2]))\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        # Get average loss for pred_len\n",
    "        loss = loss / 30\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        file1 = open(\"loss_steps.txt\", \"a\")  # append mode\n",
    "        file1.write(str(loss.item()) + \",\")\n",
    "        file1.close()\n",
    "        \n",
    "#       output = model(data)\n",
    "#         loss = MSELoss(output, target)\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8e416d099f45b89fab742c800c93b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2060.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "encoder = EncoderRNN(input_size=2)\n",
    "decoder = DecoderRNN(output_size=2)\n",
    "\n",
    "encoder = nn.DataParallel(encoder)\n",
    "decoder = nn.DataParallel(decoder)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "num_epoch = 1\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    train(encoder, decoder, device, train_all_loader, encoder_optimizer, decoder_optimizer, epoch)\n",
    "#         train(encoder, decoder, device, train_agent_loader, encoder_optimizer, decoder_optimizer, epoch)\n",
    "#         predict(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_absolute(\n",
    "        test_loader: torch.utils.data.DataLoader,\n",
    "        encoder: EncoderRNN,\n",
    "        decoder: DecoderRNN,\n",
    "#         start_idx: int,\n",
    "#         forecasted_save_dir: str,\n",
    "#         model_utils: ModelUtils,\n",
    "):\n",
    "    \"\"\"Infer function for non-map LSTM baselines and save the forecasted trajectories.\n",
    "    \n",
    "    referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\n",
    "    \n",
    "    Args:\n",
    "        test_loader: DataLoader for the test set\n",
    "        encoder: Encoder network instance\n",
    "        decoder: Decoder network instance\n",
    "        start_idx: start index for the current joblib batch\n",
    "        forecasted_save_dir: Directory where forecasted trajectories are to be saved\n",
    "        model_utils: ModelUtils instance\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    forecasted_trajectories = {}\n",
    "\n",
    "    for i, (_input, idx) in enumerate(test_loader):\n",
    "        \n",
    "#         _input = _input[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(_input.shape[0]):\n",
    "            x_offset.append(_input[i][0][0].detach().clone())\n",
    "            y_offset.append(_input[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(_input.shape[0]):\n",
    "            for i in range(_input.shape[1]):\n",
    "                _input[j][i][0] = _input[j][i][0] - x_offset[j]\n",
    "                _input[j][i][1] = _input[j][i][1] - y_offset[j]\n",
    "\n",
    "        _input = _input.to(device)\n",
    "\n",
    "        # Set to eval mode\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        input_shape = _input.shape[2]\n",
    "\n",
    "        # Initialize encoder hidden state\n",
    "        encoder_hidden = (torch.zeros(batch_size, encoder.module.hidden_size).to(device), \n",
    "                          torch.zeros(batch_size, encoder.module.hidden_size).to(device))\n",
    "       \n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_outputs = torch.zeros(\n",
    "            (batch_size, 30, 2)).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        for i in range(30):\n",
    "            for j in range(batch_size):\n",
    "                decoder_outputs[j,i,0] = decoder_outputs[j,i,0] + x_offset[j]\n",
    "                decoder_outputs[j,i,1] = decoder_outputs[j,i,1] + y_offset[j]\n",
    "            \n",
    "                if (idx[j][0][0][0] in forecasted_trajectories):\n",
    "                    forecasted_trajectories[idx[j][0][0][0]].append(decoder_outputs[j,i,:].tolist())\n",
    "                else:\n",
    "                    forecasted_trajectories[idx[j][0][0][0]] = [decoder_outputs[j,i,:].tolist()]\n",
    "                \n",
    "    return(forecasted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = infer_absolute(test_loader, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9016</th>\n",
       "      <td>[234.31005859375, 1363.3331298828125]</td>\n",
       "      <td>[233.4396209716797, 1361.9183349609375]</td>\n",
       "      <td>[233.26112365722656, 1361.655517578125]</td>\n",
       "      <td>[233.138427734375, 1361.5330810546875]</td>\n",
       "      <td>[232.91961669921875, 1361.3482666015625]</td>\n",
       "      <td>[232.47251892089844, 1360.9827880859375]</td>\n",
       "      <td>[231.7026824951172, 1360.358154296875]</td>\n",
       "      <td>[230.7525177001953, 1359.5892333984375]</td>\n",
       "      <td>[229.95875549316406, 1358.9473876953125]</td>\n",
       "      <td>[229.47557067871094, 1358.5567626953125]</td>\n",
       "      <td>...</td>\n",
       "      <td>[229.0413818359375, 1358.2030029296875]</td>\n",
       "      <td>[229.04232788085938, 1358.2034912109375]</td>\n",
       "      <td>[229.04327392578125, 1358.2041015625]</td>\n",
       "      <td>[229.04425048828125, 1358.20458984375]</td>\n",
       "      <td>[229.0452117919922, 1358.205078125]</td>\n",
       "      <td>[229.0461883544922, 1358.20556640625]</td>\n",
       "      <td>[229.04714965820312, 1358.2060546875]</td>\n",
       "      <td>[229.04812622070312, 1358.20654296875]</td>\n",
       "      <td>[229.04910278320312, 1358.20703125]</td>\n",
       "      <td>[229.05007934570312, 1358.2076416015625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12770</th>\n",
       "      <td>[1823.99951171875, 430.30401611328125]</td>\n",
       "      <td>[1824.6781005859375, 431.106689453125]</td>\n",
       "      <td>[1824.9744873046875, 431.6295471191406]</td>\n",
       "      <td>[1825.1258544921875, 432.14044189453125]</td>\n",
       "      <td>[1825.24072265625, 432.7698669433594]</td>\n",
       "      <td>[1825.3531494140625, 433.53033447265625]</td>\n",
       "      <td>[1825.4608154296875, 434.3126525878906]</td>\n",
       "      <td>[1825.54638671875, 434.9490051269531]</td>\n",
       "      <td>[1825.6007080078125, 435.3540954589844]</td>\n",
       "      <td>[1825.6295166015625, 435.56658935546875]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1825.6553955078125, 435.7427978515625]</td>\n",
       "      <td>[1825.6553955078125, 435.7428283691406]</td>\n",
       "      <td>[1825.6553955078125, 435.74285888671875]</td>\n",
       "      <td>[1825.655517578125, 435.7428894042969]</td>\n",
       "      <td>[1825.655517578125, 435.7428894042969]</td>\n",
       "      <td>[1825.655517578125, 435.7428894042969]</td>\n",
       "      <td>[1825.655517578125, 435.742919921875]</td>\n",
       "      <td>[1825.655517578125, 435.742919921875]</td>\n",
       "      <td>[1825.655517578125, 435.742919921875]</td>\n",
       "      <td>[1825.655517578125, 435.742919921875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34897</th>\n",
       "      <td>[1812.036865234375, 430.17877197265625]</td>\n",
       "      <td>[1810.2088623046875, 428.22845458984375]</td>\n",
       "      <td>[1808.7978515625, 427.1519470214844]</td>\n",
       "      <td>[1807.6353759765625, 426.3677062988281]</td>\n",
       "      <td>[1806.8240966796875, 425.8850402832031]</td>\n",
       "      <td>[1806.3038330078125, 425.517578125]</td>\n",
       "      <td>[1805.9368896484375, 424.9245910644531]</td>\n",
       "      <td>[1805.6182861328125, 423.8333740234375]</td>\n",
       "      <td>[1805.34375, 422.5434265136719]</td>\n",
       "      <td>[1805.175048828125, 421.72808837890625]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1805.65625, 418.00836181640625]</td>\n",
       "      <td>[1805.788818359375, 417.31561279296875]</td>\n",
       "      <td>[1805.8603515625, 416.9420166015625]</td>\n",
       "      <td>[1805.888916015625, 416.792724609375]</td>\n",
       "      <td>[1805.898681640625, 416.7416076660156]</td>\n",
       "      <td>[1805.90185546875, 416.72509765625]</td>\n",
       "      <td>[1805.90283203125, 416.71990966796875]</td>\n",
       "      <td>[1805.9031982421875, 416.7182922363281]</td>\n",
       "      <td>[1805.9031982421875, 416.7177734375]</td>\n",
       "      <td>[1805.9033203125, 416.7176208496094]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34978</th>\n",
       "      <td>[702.3152465820312, 1145.075927734375]</td>\n",
       "      <td>[701.1241455078125, 1141.653076171875]</td>\n",
       "      <td>[700.4012451171875, 1138.6319580078125]</td>\n",
       "      <td>[700.0833129882812, 1136.9151611328125]</td>\n",
       "      <td>[699.741455078125, 1136.0157470703125]</td>\n",
       "      <td>[699.2310791015625, 1135.2945556640625]</td>\n",
       "      <td>[698.6336669921875, 1134.6197509765625]</td>\n",
       "      <td>[698.096923828125, 1134.06005859375]</td>\n",
       "      <td>[697.7144775390625, 1133.670654296875]</td>\n",
       "      <td>[697.4865112304688, 1133.4366455078125]</td>\n",
       "      <td>...</td>\n",
       "      <td>[697.2734375, 1133.1754150390625]</td>\n",
       "      <td>[697.2750244140625, 1133.1756591796875]</td>\n",
       "      <td>[697.276611328125, 1133.1759033203125]</td>\n",
       "      <td>[697.2780151367188, 1133.17626953125]</td>\n",
       "      <td>[697.2794189453125, 1133.1766357421875]</td>\n",
       "      <td>[697.28076171875, 1133.177001953125]</td>\n",
       "      <td>[697.2820434570312, 1133.1773681640625]</td>\n",
       "      <td>[697.2833251953125, 1133.1778564453125]</td>\n",
       "      <td>[697.2845458984375, 1133.17822265625]</td>\n",
       "      <td>[697.2857666015625, 1133.1787109375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15978</th>\n",
       "      <td>[1666.2255859375, 288.8434143066406]</td>\n",
       "      <td>[1667.19091796875, 289.3826599121094]</td>\n",
       "      <td>[1667.4456787109375, 289.5143127441406]</td>\n",
       "      <td>[1667.9674072265625, 289.9256591796875]</td>\n",
       "      <td>[1669.2099609375, 290.9508361816406]</td>\n",
       "      <td>[1670.527587890625, 292.0140075683594]</td>\n",
       "      <td>[1671.1322021484375, 292.4914855957031]</td>\n",
       "      <td>[1671.317138671875, 292.6434631347656]</td>\n",
       "      <td>[1671.3876953125, 292.71484375]</td>\n",
       "      <td>[1671.443359375, 292.7869873046875]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1674.13232421875, 296.9613952636719]</td>\n",
       "      <td>[1674.1591796875, 297.01422119140625]</td>\n",
       "      <td>[1674.1722412109375, 297.0489807128906]</td>\n",
       "      <td>[1674.1790771484375, 297.0778503417969]</td>\n",
       "      <td>[1674.1832275390625, 297.10736083984375]</td>\n",
       "      <td>[1674.1866455078125, 297.141357421875]</td>\n",
       "      <td>[1674.1903076171875, 297.1825256347656]</td>\n",
       "      <td>[1674.1947021484375, 297.2332763671875]</td>\n",
       "      <td>[1674.2003173828125, 297.2959899902344]</td>\n",
       "      <td>[1674.207763671875, 297.3732604980469]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29848</th>\n",
       "      <td>[2152.728515625, 815.5418701171875]</td>\n",
       "      <td>[2151.61669921875, 814.3832397460938]</td>\n",
       "      <td>[2151.203857421875, 814.1693725585938]</td>\n",
       "      <td>[2151.01171875, 814.2684326171875]</td>\n",
       "      <td>[2150.86181640625, 814.3343505859375]</td>\n",
       "      <td>[2150.72607421875, 814.341796875]</td>\n",
       "      <td>[2150.5927734375, 814.3024291992188]</td>\n",
       "      <td>[2150.454345703125, 814.2237548828125]</td>\n",
       "      <td>[2150.304443359375, 814.1071166992188]</td>\n",
       "      <td>[2150.13623046875, 813.9506225585938]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2147.942626953125, 812.3611450195312]</td>\n",
       "      <td>[2147.7880859375, 812.3976440429688]</td>\n",
       "      <td>[2147.630859375, 812.43896484375]</td>\n",
       "      <td>[2147.46923828125, 812.4794921875]</td>\n",
       "      <td>[2147.30224609375, 812.5137939453125]</td>\n",
       "      <td>[2147.127197265625, 812.5350341796875]</td>\n",
       "      <td>[2146.93896484375, 812.532958984375]</td>\n",
       "      <td>[2146.725830078125, 812.4902954101562]</td>\n",
       "      <td>[2146.466064453125, 812.3773193359375]</td>\n",
       "      <td>[2146.12109375, 812.1455078125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13067</th>\n",
       "      <td>[746.6484985351562, 1280.489013671875]</td>\n",
       "      <td>[746.61181640625, 1282.011474609375]</td>\n",
       "      <td>[746.5973510742188, 1283.1156005859375]</td>\n",
       "      <td>[746.4915161132812, 1283.479248046875]</td>\n",
       "      <td>[746.327392578125, 1283.608154296875]</td>\n",
       "      <td>[746.1281127929688, 1283.6934814453125]</td>\n",
       "      <td>[745.9071044921875, 1283.78515625]</td>\n",
       "      <td>[745.6790771484375, 1283.9061279296875]</td>\n",
       "      <td>[745.4616088867188, 1284.0771484375]</td>\n",
       "      <td>[745.2730102539062, 1284.32080078125]</td>\n",
       "      <td>...</td>\n",
       "      <td>[746.055908203125, 1290.077880859375]</td>\n",
       "      <td>[746.3155517578125, 1290.4130859375]</td>\n",
       "      <td>[746.5574340820312, 1290.7269287109375]</td>\n",
       "      <td>[746.7822875976562, 1291.0223388671875]</td>\n",
       "      <td>[746.9929809570312, 1291.302490234375]</td>\n",
       "      <td>[747.1929321289062, 1291.570556640625]</td>\n",
       "      <td>[747.3850708007812, 1291.8291015625]</td>\n",
       "      <td>[747.57177734375, 1292.080078125]</td>\n",
       "      <td>[747.7545776367188, 1292.3251953125]</td>\n",
       "      <td>[747.9346923828125, 1292.565185546875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36574</th>\n",
       "      <td>[474.18994140625, 1144.4700927734375]</td>\n",
       "      <td>[472.9609069824219, 1144.359130859375]</td>\n",
       "      <td>[472.072998046875, 1144.3292236328125]</td>\n",
       "      <td>[471.36895751953125, 1144.3687744140625]</td>\n",
       "      <td>[470.80743408203125, 1144.4771728515625]</td>\n",
       "      <td>[470.36053466796875, 1144.5943603515625]</td>\n",
       "      <td>[470.0199890136719, 1144.680908203125]</td>\n",
       "      <td>[469.77667236328125, 1144.7265625]</td>\n",
       "      <td>[469.61309814453125, 1144.7398681640625]</td>\n",
       "      <td>[469.4996643066406, 1144.726806640625]</td>\n",
       "      <td>...</td>\n",
       "      <td>[468.7509460449219, 1144.1156005859375]</td>\n",
       "      <td>[468.7232971191406, 1144.090087890625]</td>\n",
       "      <td>[468.6996765136719, 1144.0684814453125]</td>\n",
       "      <td>[468.6795654296875, 1144.0504150390625]</td>\n",
       "      <td>[468.66259765625, 1144.03564453125]</td>\n",
       "      <td>[468.6484375, 1144.0235595703125]</td>\n",
       "      <td>[468.6368103027344, 1144.01416015625]</td>\n",
       "      <td>[468.6274719238281, 1144.007080078125]</td>\n",
       "      <td>[468.6202087402344, 1144.002197265625]</td>\n",
       "      <td>[468.6148681640625, 1143.999267578125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20847</th>\n",
       "      <td>[573.6171264648438, 1528.95654296875]</td>\n",
       "      <td>[573.5437622070312, 1528.9306640625]</td>\n",
       "      <td>[573.5775756835938, 1528.909912109375]</td>\n",
       "      <td>[573.8362426757812, 1528.9864501953125]</td>\n",
       "      <td>[574.3062744140625, 1529.1416015625]</td>\n",
       "      <td>[574.9119262695312, 1529.316162109375]</td>\n",
       "      <td>[575.5831298828125, 1529.4739990234375]</td>\n",
       "      <td>[576.228515625, 1529.592041015625]</td>\n",
       "      <td>[576.7373657226562, 1529.651123046875]</td>\n",
       "      <td>[577.0533447265625, 1529.6483154296875]</td>\n",
       "      <td>...</td>\n",
       "      <td>[576.77978515625, 1528.667724609375]</td>\n",
       "      <td>[576.7115478515625, 1528.5753173828125]</td>\n",
       "      <td>[576.644775390625, 1528.4879150390625]</td>\n",
       "      <td>[576.5802001953125, 1528.4066162109375]</td>\n",
       "      <td>[576.5184326171875, 1528.3321533203125]</td>\n",
       "      <td>[576.4598388671875, 1528.2652587890625]</td>\n",
       "      <td>[576.4048461914062, 1528.2059326171875]</td>\n",
       "      <td>[576.3534545898438, 1528.1541748046875]</td>\n",
       "      <td>[576.3056030273438, 1528.109375]</td>\n",
       "      <td>[576.2611694335938, 1528.0711669921875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37896</th>\n",
       "      <td>[589.8040771484375, 1525.8570556640625]</td>\n",
       "      <td>[591.7142333984375, 1526.8988037109375]</td>\n",
       "      <td>[592.9942626953125, 1527.6085205078125]</td>\n",
       "      <td>[593.870849609375, 1528.0552978515625]</td>\n",
       "      <td>[594.1881103515625, 1528.073974609375]</td>\n",
       "      <td>[594.1922607421875, 1527.86279296875]</td>\n",
       "      <td>[594.11474609375, 1527.626953125]</td>\n",
       "      <td>[594.03759765625, 1527.439208984375]</td>\n",
       "      <td>[593.9805297851562, 1527.30908203125]</td>\n",
       "      <td>[593.94775390625, 1527.232177734375]</td>\n",
       "      <td>...</td>\n",
       "      <td>[595.7415771484375, 1530.0123291015625]</td>\n",
       "      <td>[595.8619384765625, 1530.211181640625]</td>\n",
       "      <td>[595.941162109375, 1530.34716796875]</td>\n",
       "      <td>[595.9920043945312, 1530.4405517578125]</td>\n",
       "      <td>[596.0250244140625, 1530.5078125]</td>\n",
       "      <td>[596.047607421875, 1530.560546875]</td>\n",
       "      <td>[596.0643920898438, 1530.606201171875]</td>\n",
       "      <td>[596.0784912109375, 1530.64990234375]</td>\n",
       "      <td>[596.0916748046875, 1530.6947021484375]</td>\n",
       "      <td>[596.1051025390625, 1530.7425537109375]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0   \\\n",
       "9016     [234.31005859375, 1363.3331298828125]   \n",
       "12770   [1823.99951171875, 430.30401611328125]   \n",
       "34897  [1812.036865234375, 430.17877197265625]   \n",
       "34978   [702.3152465820312, 1145.075927734375]   \n",
       "15978     [1666.2255859375, 288.8434143066406]   \n",
       "...                                        ...   \n",
       "29848      [2152.728515625, 815.5418701171875]   \n",
       "13067   [746.6484985351562, 1280.489013671875]   \n",
       "36574    [474.18994140625, 1144.4700927734375]   \n",
       "20847    [573.6171264648438, 1528.95654296875]   \n",
       "37896  [589.8040771484375, 1525.8570556640625]   \n",
       "\n",
       "                                             1   \\\n",
       "9016    [233.4396209716797, 1361.9183349609375]   \n",
       "12770    [1824.6781005859375, 431.106689453125]   \n",
       "34897  [1810.2088623046875, 428.22845458984375]   \n",
       "34978    [701.1241455078125, 1141.653076171875]   \n",
       "15978     [1667.19091796875, 289.3826599121094]   \n",
       "...                                         ...   \n",
       "29848     [2151.61669921875, 814.3832397460938]   \n",
       "13067      [746.61181640625, 1282.011474609375]   \n",
       "36574    [472.9609069824219, 1144.359130859375]   \n",
       "20847      [573.5437622070312, 1528.9306640625]   \n",
       "37896   [591.7142333984375, 1526.8988037109375]   \n",
       "\n",
       "                                            2   \\\n",
       "9016   [233.26112365722656, 1361.655517578125]   \n",
       "12770  [1824.9744873046875, 431.6295471191406]   \n",
       "34897     [1808.7978515625, 427.1519470214844]   \n",
       "34978  [700.4012451171875, 1138.6319580078125]   \n",
       "15978  [1667.4456787109375, 289.5143127441406]   \n",
       "...                                        ...   \n",
       "29848   [2151.203857421875, 814.1693725585938]   \n",
       "13067  [746.5973510742188, 1283.1156005859375]   \n",
       "36574   [472.072998046875, 1144.3292236328125]   \n",
       "20847   [573.5775756835938, 1528.909912109375]   \n",
       "37896  [592.9942626953125, 1527.6085205078125]   \n",
       "\n",
       "                                             3   \\\n",
       "9016     [233.138427734375, 1361.5330810546875]   \n",
       "12770  [1825.1258544921875, 432.14044189453125]   \n",
       "34897   [1807.6353759765625, 426.3677062988281]   \n",
       "34978   [700.0833129882812, 1136.9151611328125]   \n",
       "15978   [1667.9674072265625, 289.9256591796875]   \n",
       "...                                         ...   \n",
       "29848        [2151.01171875, 814.2684326171875]   \n",
       "13067    [746.4915161132812, 1283.479248046875]   \n",
       "36574  [471.36895751953125, 1144.3687744140625]   \n",
       "20847   [573.8362426757812, 1528.9864501953125]   \n",
       "37896    [593.870849609375, 1528.0552978515625]   \n",
       "\n",
       "                                             4   \\\n",
       "9016   [232.91961669921875, 1361.3482666015625]   \n",
       "12770     [1825.24072265625, 432.7698669433594]   \n",
       "34897   [1806.8240966796875, 425.8850402832031]   \n",
       "34978    [699.741455078125, 1136.0157470703125]   \n",
       "15978      [1669.2099609375, 290.9508361816406]   \n",
       "...                                         ...   \n",
       "29848     [2150.86181640625, 814.3343505859375]   \n",
       "13067     [746.327392578125, 1283.608154296875]   \n",
       "36574  [470.80743408203125, 1144.4771728515625]   \n",
       "20847      [574.3062744140625, 1529.1416015625]   \n",
       "37896    [594.1881103515625, 1528.073974609375]   \n",
       "\n",
       "                                             5   \\\n",
       "9016   [232.47251892089844, 1360.9827880859375]   \n",
       "12770  [1825.3531494140625, 433.53033447265625]   \n",
       "34897       [1806.3038330078125, 425.517578125]   \n",
       "34978   [699.2310791015625, 1135.2945556640625]   \n",
       "15978    [1670.527587890625, 292.0140075683594]   \n",
       "...                                         ...   \n",
       "29848         [2150.72607421875, 814.341796875]   \n",
       "13067   [746.1281127929688, 1283.6934814453125]   \n",
       "36574  [470.36053466796875, 1144.5943603515625]   \n",
       "20847    [574.9119262695312, 1529.316162109375]   \n",
       "37896     [594.1922607421875, 1527.86279296875]   \n",
       "\n",
       "                                            6   \\\n",
       "9016    [231.7026824951172, 1360.358154296875]   \n",
       "12770  [1825.4608154296875, 434.3126525878906]   \n",
       "34897  [1805.9368896484375, 424.9245910644531]   \n",
       "34978  [698.6336669921875, 1134.6197509765625]   \n",
       "15978  [1671.1322021484375, 292.4914855957031]   \n",
       "...                                        ...   \n",
       "29848     [2150.5927734375, 814.3024291992188]   \n",
       "13067       [745.9071044921875, 1283.78515625]   \n",
       "36574   [470.0199890136719, 1144.680908203125]   \n",
       "20847  [575.5831298828125, 1529.4739990234375]   \n",
       "37896        [594.11474609375, 1527.626953125]   \n",
       "\n",
       "                                            7   \\\n",
       "9016   [230.7525177001953, 1359.5892333984375]   \n",
       "12770    [1825.54638671875, 434.9490051269531]   \n",
       "34897  [1805.6182861328125, 423.8333740234375]   \n",
       "34978     [698.096923828125, 1134.06005859375]   \n",
       "15978   [1671.317138671875, 292.6434631347656]   \n",
       "...                                        ...   \n",
       "29848   [2150.454345703125, 814.2237548828125]   \n",
       "13067  [745.6790771484375, 1283.9061279296875]   \n",
       "36574       [469.77667236328125, 1144.7265625]   \n",
       "20847       [576.228515625, 1529.592041015625]   \n",
       "37896     [594.03759765625, 1527.439208984375]   \n",
       "\n",
       "                                             8   \\\n",
       "9016   [229.95875549316406, 1358.9473876953125]   \n",
       "12770   [1825.6007080078125, 435.3540954589844]   \n",
       "34897           [1805.34375, 422.5434265136719]   \n",
       "34978    [697.7144775390625, 1133.670654296875]   \n",
       "15978           [1671.3876953125, 292.71484375]   \n",
       "...                                         ...   \n",
       "29848    [2150.304443359375, 814.1071166992188]   \n",
       "13067      [745.4616088867188, 1284.0771484375]   \n",
       "36574  [469.61309814453125, 1144.7398681640625]   \n",
       "20847    [576.7373657226562, 1529.651123046875]   \n",
       "37896     [593.9805297851562, 1527.30908203125]   \n",
       "\n",
       "                                             9   ...  \\\n",
       "9016   [229.47557067871094, 1358.5567626953125]  ...   \n",
       "12770  [1825.6295166015625, 435.56658935546875]  ...   \n",
       "34897   [1805.175048828125, 421.72808837890625]  ...   \n",
       "34978   [697.4865112304688, 1133.4366455078125]  ...   \n",
       "15978       [1671.443359375, 292.7869873046875]  ...   \n",
       "...                                         ...  ...   \n",
       "29848     [2150.13623046875, 813.9506225585938]  ...   \n",
       "13067     [745.2730102539062, 1284.32080078125]  ...   \n",
       "36574    [469.4996643066406, 1144.726806640625]  ...   \n",
       "20847   [577.0533447265625, 1529.6483154296875]  ...   \n",
       "37896      [593.94775390625, 1527.232177734375]  ...   \n",
       "\n",
       "                                            20  \\\n",
       "9016   [229.0413818359375, 1358.2030029296875]   \n",
       "12770  [1825.6553955078125, 435.7427978515625]   \n",
       "34897         [1805.65625, 418.00836181640625]   \n",
       "34978        [697.2734375, 1133.1754150390625]   \n",
       "15978    [1674.13232421875, 296.9613952636719]   \n",
       "...                                        ...   \n",
       "29848   [2147.942626953125, 812.3611450195312]   \n",
       "13067    [746.055908203125, 1290.077880859375]   \n",
       "36574  [468.7509460449219, 1144.1156005859375]   \n",
       "20847     [576.77978515625, 1528.667724609375]   \n",
       "37896  [595.7415771484375, 1530.0123291015625]   \n",
       "\n",
       "                                             21  \\\n",
       "9016   [229.04232788085938, 1358.2034912109375]   \n",
       "12770   [1825.6553955078125, 435.7428283691406]   \n",
       "34897   [1805.788818359375, 417.31561279296875]   \n",
       "34978   [697.2750244140625, 1133.1756591796875]   \n",
       "15978     [1674.1591796875, 297.01422119140625]   \n",
       "...                                         ...   \n",
       "29848      [2147.7880859375, 812.3976440429688]   \n",
       "13067      [746.3155517578125, 1290.4130859375]   \n",
       "36574    [468.7232971191406, 1144.090087890625]   \n",
       "20847   [576.7115478515625, 1528.5753173828125]   \n",
       "37896    [595.8619384765625, 1530.211181640625]   \n",
       "\n",
       "                                             22  \\\n",
       "9016      [229.04327392578125, 1358.2041015625]   \n",
       "12770  [1825.6553955078125, 435.74285888671875]   \n",
       "34897      [1805.8603515625, 416.9420166015625]   \n",
       "34978    [697.276611328125, 1133.1759033203125]   \n",
       "15978   [1674.1722412109375, 297.0489807128906]   \n",
       "...                                         ...   \n",
       "29848         [2147.630859375, 812.43896484375]   \n",
       "13067   [746.5574340820312, 1290.7269287109375]   \n",
       "36574   [468.6996765136719, 1144.0684814453125]   \n",
       "20847    [576.644775390625, 1528.4879150390625]   \n",
       "37896      [595.941162109375, 1530.34716796875]   \n",
       "\n",
       "                                            23  \\\n",
       "9016    [229.04425048828125, 1358.20458984375]   \n",
       "12770   [1825.655517578125, 435.7428894042969]   \n",
       "34897    [1805.888916015625, 416.792724609375]   \n",
       "34978    [697.2780151367188, 1133.17626953125]   \n",
       "15978  [1674.1790771484375, 297.0778503417969]   \n",
       "...                                        ...   \n",
       "29848       [2147.46923828125, 812.4794921875]   \n",
       "13067  [746.7822875976562, 1291.0223388671875]   \n",
       "36574  [468.6795654296875, 1144.0504150390625]   \n",
       "20847  [576.5802001953125, 1528.4066162109375]   \n",
       "37896  [595.9920043945312, 1530.4405517578125]   \n",
       "\n",
       "                                             24  \\\n",
       "9016        [229.0452117919922, 1358.205078125]   \n",
       "12770    [1825.655517578125, 435.7428894042969]   \n",
       "34897    [1805.898681640625, 416.7416076660156]   \n",
       "34978   [697.2794189453125, 1133.1766357421875]   \n",
       "15978  [1674.1832275390625, 297.10736083984375]   \n",
       "...                                         ...   \n",
       "29848     [2147.30224609375, 812.5137939453125]   \n",
       "13067    [746.9929809570312, 1291.302490234375]   \n",
       "36574       [468.66259765625, 1144.03564453125]   \n",
       "20847   [576.5184326171875, 1528.3321533203125]   \n",
       "37896         [596.0250244140625, 1530.5078125]   \n",
       "\n",
       "                                            25  \\\n",
       "9016     [229.0461883544922, 1358.20556640625]   \n",
       "12770   [1825.655517578125, 435.7428894042969]   \n",
       "34897      [1805.90185546875, 416.72509765625]   \n",
       "34978     [697.28076171875, 1133.177001953125]   \n",
       "15978   [1674.1866455078125, 297.141357421875]   \n",
       "...                                        ...   \n",
       "29848   [2147.127197265625, 812.5350341796875]   \n",
       "13067   [747.1929321289062, 1291.570556640625]   \n",
       "36574        [468.6484375, 1144.0235595703125]   \n",
       "20847  [576.4598388671875, 1528.2652587890625]   \n",
       "37896       [596.047607421875, 1530.560546875]   \n",
       "\n",
       "                                            26  \\\n",
       "9016     [229.04714965820312, 1358.2060546875]   \n",
       "12770    [1825.655517578125, 435.742919921875]   \n",
       "34897   [1805.90283203125, 416.71990966796875]   \n",
       "34978  [697.2820434570312, 1133.1773681640625]   \n",
       "15978  [1674.1903076171875, 297.1825256347656]   \n",
       "...                                        ...   \n",
       "29848     [2146.93896484375, 812.532958984375]   \n",
       "13067     [747.3850708007812, 1291.8291015625]   \n",
       "36574    [468.6368103027344, 1144.01416015625]   \n",
       "20847  [576.4048461914062, 1528.2059326171875]   \n",
       "37896   [596.0643920898438, 1530.606201171875]   \n",
       "\n",
       "                                            27  \\\n",
       "9016    [229.04812622070312, 1358.20654296875]   \n",
       "12770    [1825.655517578125, 435.742919921875]   \n",
       "34897  [1805.9031982421875, 416.7182922363281]   \n",
       "34978  [697.2833251953125, 1133.1778564453125]   \n",
       "15978  [1674.1947021484375, 297.2332763671875]   \n",
       "...                                        ...   \n",
       "29848   [2146.725830078125, 812.4902954101562]   \n",
       "13067        [747.57177734375, 1292.080078125]   \n",
       "36574   [468.6274719238281, 1144.007080078125]   \n",
       "20847  [576.3534545898438, 1528.1541748046875]   \n",
       "37896    [596.0784912109375, 1530.64990234375]   \n",
       "\n",
       "                                            28  \\\n",
       "9016       [229.04910278320312, 1358.20703125]   \n",
       "12770    [1825.655517578125, 435.742919921875]   \n",
       "34897     [1805.9031982421875, 416.7177734375]   \n",
       "34978    [697.2845458984375, 1133.17822265625]   \n",
       "15978  [1674.2003173828125, 297.2959899902344]   \n",
       "...                                        ...   \n",
       "29848   [2146.466064453125, 812.3773193359375]   \n",
       "13067     [747.7545776367188, 1292.3251953125]   \n",
       "36574   [468.6202087402344, 1144.002197265625]   \n",
       "20847         [576.3056030273438, 1528.109375]   \n",
       "37896  [596.0916748046875, 1530.6947021484375]   \n",
       "\n",
       "                                             29  \n",
       "9016   [229.05007934570312, 1358.2076416015625]  \n",
       "12770     [1825.655517578125, 435.742919921875]  \n",
       "34897      [1805.9033203125, 416.7176208496094]  \n",
       "34978      [697.2857666015625, 1133.1787109375]  \n",
       "15978    [1674.207763671875, 297.3732604980469]  \n",
       "...                                         ...  \n",
       "29848           [2146.12109375, 812.1455078125]  \n",
       "13067    [747.9346923828125, 1292.565185546875]  \n",
       "36574    [468.6148681640625, 1143.999267578125]  \n",
       "20847   [576.2611694335938, 1528.0711669921875]  \n",
       "37896   [596.1051025390625, 1530.7425537109375]  \n",
       "\n",
       "[3200 rows x 30 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(output, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    df[['v{}'.format((i*2)+1), 'v{}'.format((i*2)+2)]] = pd.DataFrame(df.get(i).tolist(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9016</th>\n",
       "      <td>234.310059</td>\n",
       "      <td>1363.333130</td>\n",
       "      <td>233.439621</td>\n",
       "      <td>1361.918335</td>\n",
       "      <td>233.261124</td>\n",
       "      <td>1361.655518</td>\n",
       "      <td>233.138428</td>\n",
       "      <td>1361.533081</td>\n",
       "      <td>232.919617</td>\n",
       "      <td>1361.348267</td>\n",
       "      <td>...</td>\n",
       "      <td>229.046188</td>\n",
       "      <td>1358.205566</td>\n",
       "      <td>229.047150</td>\n",
       "      <td>1358.206055</td>\n",
       "      <td>229.048126</td>\n",
       "      <td>1358.206543</td>\n",
       "      <td>229.049103</td>\n",
       "      <td>1358.207031</td>\n",
       "      <td>229.050079</td>\n",
       "      <td>1358.207642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12770</th>\n",
       "      <td>1823.999512</td>\n",
       "      <td>430.304016</td>\n",
       "      <td>1824.678101</td>\n",
       "      <td>431.106689</td>\n",
       "      <td>1824.974487</td>\n",
       "      <td>431.629547</td>\n",
       "      <td>1825.125854</td>\n",
       "      <td>432.140442</td>\n",
       "      <td>1825.240723</td>\n",
       "      <td>432.769867</td>\n",
       "      <td>...</td>\n",
       "      <td>1825.655518</td>\n",
       "      <td>435.742889</td>\n",
       "      <td>1825.655518</td>\n",
       "      <td>435.742920</td>\n",
       "      <td>1825.655518</td>\n",
       "      <td>435.742920</td>\n",
       "      <td>1825.655518</td>\n",
       "      <td>435.742920</td>\n",
       "      <td>1825.655518</td>\n",
       "      <td>435.742920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34897</th>\n",
       "      <td>1812.036865</td>\n",
       "      <td>430.178772</td>\n",
       "      <td>1810.208862</td>\n",
       "      <td>428.228455</td>\n",
       "      <td>1808.797852</td>\n",
       "      <td>427.151947</td>\n",
       "      <td>1807.635376</td>\n",
       "      <td>426.367706</td>\n",
       "      <td>1806.824097</td>\n",
       "      <td>425.885040</td>\n",
       "      <td>...</td>\n",
       "      <td>1805.901855</td>\n",
       "      <td>416.725098</td>\n",
       "      <td>1805.902832</td>\n",
       "      <td>416.719910</td>\n",
       "      <td>1805.903198</td>\n",
       "      <td>416.718292</td>\n",
       "      <td>1805.903198</td>\n",
       "      <td>416.717773</td>\n",
       "      <td>1805.903320</td>\n",
       "      <td>416.717621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34978</th>\n",
       "      <td>702.315247</td>\n",
       "      <td>1145.075928</td>\n",
       "      <td>701.124146</td>\n",
       "      <td>1141.653076</td>\n",
       "      <td>700.401245</td>\n",
       "      <td>1138.631958</td>\n",
       "      <td>700.083313</td>\n",
       "      <td>1136.915161</td>\n",
       "      <td>699.741455</td>\n",
       "      <td>1136.015747</td>\n",
       "      <td>...</td>\n",
       "      <td>697.280762</td>\n",
       "      <td>1133.177002</td>\n",
       "      <td>697.282043</td>\n",
       "      <td>1133.177368</td>\n",
       "      <td>697.283325</td>\n",
       "      <td>1133.177856</td>\n",
       "      <td>697.284546</td>\n",
       "      <td>1133.178223</td>\n",
       "      <td>697.285767</td>\n",
       "      <td>1133.178711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15978</th>\n",
       "      <td>1666.225586</td>\n",
       "      <td>288.843414</td>\n",
       "      <td>1667.190918</td>\n",
       "      <td>289.382660</td>\n",
       "      <td>1667.445679</td>\n",
       "      <td>289.514313</td>\n",
       "      <td>1667.967407</td>\n",
       "      <td>289.925659</td>\n",
       "      <td>1669.209961</td>\n",
       "      <td>290.950836</td>\n",
       "      <td>...</td>\n",
       "      <td>1674.186646</td>\n",
       "      <td>297.141357</td>\n",
       "      <td>1674.190308</td>\n",
       "      <td>297.182526</td>\n",
       "      <td>1674.194702</td>\n",
       "      <td>297.233276</td>\n",
       "      <td>1674.200317</td>\n",
       "      <td>297.295990</td>\n",
       "      <td>1674.207764</td>\n",
       "      <td>297.373260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29848</th>\n",
       "      <td>2152.728516</td>\n",
       "      <td>815.541870</td>\n",
       "      <td>2151.616699</td>\n",
       "      <td>814.383240</td>\n",
       "      <td>2151.203857</td>\n",
       "      <td>814.169373</td>\n",
       "      <td>2151.011719</td>\n",
       "      <td>814.268433</td>\n",
       "      <td>2150.861816</td>\n",
       "      <td>814.334351</td>\n",
       "      <td>...</td>\n",
       "      <td>2147.127197</td>\n",
       "      <td>812.535034</td>\n",
       "      <td>2146.938965</td>\n",
       "      <td>812.532959</td>\n",
       "      <td>2146.725830</td>\n",
       "      <td>812.490295</td>\n",
       "      <td>2146.466064</td>\n",
       "      <td>812.377319</td>\n",
       "      <td>2146.121094</td>\n",
       "      <td>812.145508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13067</th>\n",
       "      <td>746.648499</td>\n",
       "      <td>1280.489014</td>\n",
       "      <td>746.611816</td>\n",
       "      <td>1282.011475</td>\n",
       "      <td>746.597351</td>\n",
       "      <td>1283.115601</td>\n",
       "      <td>746.491516</td>\n",
       "      <td>1283.479248</td>\n",
       "      <td>746.327393</td>\n",
       "      <td>1283.608154</td>\n",
       "      <td>...</td>\n",
       "      <td>747.192932</td>\n",
       "      <td>1291.570557</td>\n",
       "      <td>747.385071</td>\n",
       "      <td>1291.829102</td>\n",
       "      <td>747.571777</td>\n",
       "      <td>1292.080078</td>\n",
       "      <td>747.754578</td>\n",
       "      <td>1292.325195</td>\n",
       "      <td>747.934692</td>\n",
       "      <td>1292.565186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36574</th>\n",
       "      <td>474.189941</td>\n",
       "      <td>1144.470093</td>\n",
       "      <td>472.960907</td>\n",
       "      <td>1144.359131</td>\n",
       "      <td>472.072998</td>\n",
       "      <td>1144.329224</td>\n",
       "      <td>471.368958</td>\n",
       "      <td>1144.368774</td>\n",
       "      <td>470.807434</td>\n",
       "      <td>1144.477173</td>\n",
       "      <td>...</td>\n",
       "      <td>468.648438</td>\n",
       "      <td>1144.023560</td>\n",
       "      <td>468.636810</td>\n",
       "      <td>1144.014160</td>\n",
       "      <td>468.627472</td>\n",
       "      <td>1144.007080</td>\n",
       "      <td>468.620209</td>\n",
       "      <td>1144.002197</td>\n",
       "      <td>468.614868</td>\n",
       "      <td>1143.999268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20847</th>\n",
       "      <td>573.617126</td>\n",
       "      <td>1528.956543</td>\n",
       "      <td>573.543762</td>\n",
       "      <td>1528.930664</td>\n",
       "      <td>573.577576</td>\n",
       "      <td>1528.909912</td>\n",
       "      <td>573.836243</td>\n",
       "      <td>1528.986450</td>\n",
       "      <td>574.306274</td>\n",
       "      <td>1529.141602</td>\n",
       "      <td>...</td>\n",
       "      <td>576.459839</td>\n",
       "      <td>1528.265259</td>\n",
       "      <td>576.404846</td>\n",
       "      <td>1528.205933</td>\n",
       "      <td>576.353455</td>\n",
       "      <td>1528.154175</td>\n",
       "      <td>576.305603</td>\n",
       "      <td>1528.109375</td>\n",
       "      <td>576.261169</td>\n",
       "      <td>1528.071167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37896</th>\n",
       "      <td>589.804077</td>\n",
       "      <td>1525.857056</td>\n",
       "      <td>591.714233</td>\n",
       "      <td>1526.898804</td>\n",
       "      <td>592.994263</td>\n",
       "      <td>1527.608521</td>\n",
       "      <td>593.870850</td>\n",
       "      <td>1528.055298</td>\n",
       "      <td>594.188110</td>\n",
       "      <td>1528.073975</td>\n",
       "      <td>...</td>\n",
       "      <td>596.047607</td>\n",
       "      <td>1530.560547</td>\n",
       "      <td>596.064392</td>\n",
       "      <td>1530.606201</td>\n",
       "      <td>596.078491</td>\n",
       "      <td>1530.649902</td>\n",
       "      <td>596.091675</td>\n",
       "      <td>1530.694702</td>\n",
       "      <td>596.105103</td>\n",
       "      <td>1530.742554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                v1           v2           v3           v4           v5  \\\n",
       "ID                                                                       \n",
       "9016    234.310059  1363.333130   233.439621  1361.918335   233.261124   \n",
       "12770  1823.999512   430.304016  1824.678101   431.106689  1824.974487   \n",
       "34897  1812.036865   430.178772  1810.208862   428.228455  1808.797852   \n",
       "34978   702.315247  1145.075928   701.124146  1141.653076   700.401245   \n",
       "15978  1666.225586   288.843414  1667.190918   289.382660  1667.445679   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29848  2152.728516   815.541870  2151.616699   814.383240  2151.203857   \n",
       "13067   746.648499  1280.489014   746.611816  1282.011475   746.597351   \n",
       "36574   474.189941  1144.470093   472.960907  1144.359131   472.072998   \n",
       "20847   573.617126  1528.956543   573.543762  1528.930664   573.577576   \n",
       "37896   589.804077  1525.857056   591.714233  1526.898804   592.994263   \n",
       "\n",
       "                v6           v7           v8           v9          v10  ...  \\\n",
       "ID                                                                      ...   \n",
       "9016   1361.655518   233.138428  1361.533081   232.919617  1361.348267  ...   \n",
       "12770   431.629547  1825.125854   432.140442  1825.240723   432.769867  ...   \n",
       "34897   427.151947  1807.635376   426.367706  1806.824097   425.885040  ...   \n",
       "34978  1138.631958   700.083313  1136.915161   699.741455  1136.015747  ...   \n",
       "15978   289.514313  1667.967407   289.925659  1669.209961   290.950836  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "29848   814.169373  2151.011719   814.268433  2150.861816   814.334351  ...   \n",
       "13067  1283.115601   746.491516  1283.479248   746.327393  1283.608154  ...   \n",
       "36574  1144.329224   471.368958  1144.368774   470.807434  1144.477173  ...   \n",
       "20847  1528.909912   573.836243  1528.986450   574.306274  1529.141602  ...   \n",
       "37896  1527.608521   593.870850  1528.055298   594.188110  1528.073975  ...   \n",
       "\n",
       "               v51          v52          v53          v54          v55  \\\n",
       "ID                                                                       \n",
       "9016    229.046188  1358.205566   229.047150  1358.206055   229.048126   \n",
       "12770  1825.655518   435.742889  1825.655518   435.742920  1825.655518   \n",
       "34897  1805.901855   416.725098  1805.902832   416.719910  1805.903198   \n",
       "34978   697.280762  1133.177002   697.282043  1133.177368   697.283325   \n",
       "15978  1674.186646   297.141357  1674.190308   297.182526  1674.194702   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29848  2147.127197   812.535034  2146.938965   812.532959  2146.725830   \n",
       "13067   747.192932  1291.570557   747.385071  1291.829102   747.571777   \n",
       "36574   468.648438  1144.023560   468.636810  1144.014160   468.627472   \n",
       "20847   576.459839  1528.265259   576.404846  1528.205933   576.353455   \n",
       "37896   596.047607  1530.560547   596.064392  1530.606201   596.078491   \n",
       "\n",
       "               v56          v57          v58          v59          v60  \n",
       "ID                                                                      \n",
       "9016   1358.206543   229.049103  1358.207031   229.050079  1358.207642  \n",
       "12770   435.742920  1825.655518   435.742920  1825.655518   435.742920  \n",
       "34897   416.718292  1805.903198   416.717773  1805.903320   416.717621  \n",
       "34978  1133.177856   697.284546  1133.178223   697.285767  1133.178711  \n",
       "15978   297.233276  1674.200317   297.295990  1674.207764   297.373260  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "29848   812.490295  2146.466064   812.377319  2146.121094   812.145508  \n",
       "13067  1292.080078   747.754578  1292.325195   747.934692  1292.565186  \n",
       "36574  1144.007080   468.620209  1144.002197   468.614868  1143.999268  \n",
       "20847  1528.154175   576.305603  1528.109375   576.261169  1528.071167  \n",
       "37896  1530.649902   596.091675  1530.694702   596.105103  1530.742554  \n",
       "\n",
       "[3200 rows x 60 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dropped_cols = list(np.arange(30))\n",
    "df2 = df.drop(dropped_cols, axis=1)\n",
    "df2.index.name = 'ID'\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"outputs1ep_train.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
