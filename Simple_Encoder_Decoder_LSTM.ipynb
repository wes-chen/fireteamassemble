{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy\n",
    "import pickle\n",
    "from glob import glob\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "test_path = './new_val_in/new_val_in'\n",
    "subset_test_path = './new_train/train_subset'\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "test_dataset = ArgoverseDataset(data_path=test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def train_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch]\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch]\n",
    "    inp = torch.Tensor(inp)\n",
    "    idx = [numpy.dstack([scene['scene_idx']]) for scene in batch]\n",
    "    return inp, idx\n",
    "    \n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_collate, num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz, shuffle = True, collate_fn=test_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size = 2,\n",
    "                 embedding_size = 8,\n",
    "                 hidden_size = 16):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = F.relu(self.linear(x))\n",
    "        hidden = self.lstm(embedded, hidden)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"Decoder Network.\"\"\"\n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    def __init__(self, embedding_size=8, hidden_size=16, output_size=2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.linear1 = nn.Linear(output_size, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = F.relu(self.linear1(x))\n",
    "        hidden = self.lstm(embedded, hidden)\n",
    "        output = self.linear2(hidden[0])\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def train(encoder, decoder, device, train_loader, encoder_optimizer, decoder_optimizer, epoch, log_interval=10000):    \n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    \n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        \n",
    "        inp, out = sample_batch\n",
    "        # preprocessing more ????\n",
    "        inp = inp[:,0,:,:]\n",
    "        out = out[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(inp.shape[0]):\n",
    "            x_offset.append(inp[i][0][0].detach().clone())\n",
    "            y_offset.append(inp[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(inp.shape[0]):\n",
    "            for i in range(inp.shape[1]):\n",
    "                inp[j][i][0] = inp[j][i][0] - x_offset[j]\n",
    "                inp[j][i][1] = inp[j][i][1] - y_offset[j]\n",
    "\n",
    "        #outoput whatever\n",
    "        for j in range(out.shape[0]):\n",
    "            for i in range(out.shape[1]):\n",
    "                out[j][i][0] = out[j][i][0] - x_offset[j]\n",
    "                out[j][i][1] = out[j][i][1] - y_offset[j]\n",
    "        \n",
    "        _input, target = inp.to(device), out.to(device)\n",
    "        \n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        #encoder \n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        output_length = target.shape[1]\n",
    "        feature_len = _input.shape[2]\n",
    "        input_shape = _input.shape[2]\n",
    "        \n",
    "        encoder_hidden = (torch.zeros(batch_size, encoder.module.hidden_size).to(device), \n",
    "                          torch.zeros(batch_size, encoder.module.hidden_size).to(device))\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_outputs = torch.zeros(target.shape).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Update loss\n",
    "            loss += torch.sqrt(criterion(decoder_output[:, :2], target[:, di, :2]))\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        # Get average loss for pred_len\n",
    "        loss = loss / 30\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        file1 = open(\"loss_steps.txt\", \"a\")  # append mode\n",
    "        file1.write(str(loss.item()) + \",\")\n",
    "        file1.close()\n",
    "        \n",
    "#       output = model(data)\n",
    "#         loss = MSELoss(output, target)\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d429ea410080479b8430b8b20d83858c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f663ed84132c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#         predict(model, device, test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-f92dc4605644>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, device, train_loader, encoder_optimizer, decoder_optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Backpropagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "encoder = EncoderRNN(input_size=2)\n",
    "decoder = DecoderRNN(output_size=2)\n",
    "\n",
    "encoder = nn.DataParallel(encoder)\n",
    "decoder = nn.DataParallel(decoder)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "num_epoch = 1\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(encoder, decoder, device, val_loader, encoder_optimizer, decoder_optimizer, epoch)\n",
    "#         predict(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_absolute(\n",
    "        test_loader: torch.utils.data.DataLoader,\n",
    "        encoder: EncoderRNN,\n",
    "        decoder: DecoderRNN,\n",
    "#         start_idx: int,\n",
    "#         forecasted_save_dir: str,\n",
    "#         model_utils: ModelUtils,\n",
    "):\n",
    "    \"\"\"Infer function for non-map LSTM baselines and save the forecasted trajectories.\n",
    "    \n",
    "    referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\n",
    "    \n",
    "    Args:\n",
    "        test_loader: DataLoader for the test set\n",
    "        encoder: Encoder network instance\n",
    "        decoder: Decoder network instance\n",
    "        start_idx: start index for the current joblib batch\n",
    "        forecasted_save_dir: Directory where forecasted trajectories are to be saved\n",
    "        model_utils: ModelUtils instance\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    forecasted_trajectories = {}\n",
    "\n",
    "    for i, (_input, idx) in enumerate(test_loader):\n",
    "        \n",
    "        _input = _input[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(_input.shape[0]):\n",
    "            x_offset.append(_input[i][0][0].detach().clone())\n",
    "            y_offset.append(_input[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(_input.shape[0]):\n",
    "            for i in range(_input.shape[1]):\n",
    "                _input[j][i][0] = _input[j][i][0] - x_offset[j]\n",
    "                _input[j][i][1] = _input[j][i][1] - y_offset[j]\n",
    "\n",
    "        _input = _input.to(device)\n",
    "\n",
    "        # Set to eval mode\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        input_shape = _input.shape[2]\n",
    "\n",
    "        # Initialize encoder hidden state\n",
    "        encoder_hidden = (torch.zeros(batch_size, encoder.module.hidden_size).to(device), \n",
    "                          torch.zeros(batch_size, encoder.module.hidden_size).to(device))\n",
    "       \n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_outputs = torch.zeros(\n",
    "            (batch_size, 30, 2)).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        for i in range(30):\n",
    "            for j in range(batch_size):\n",
    "                decoder_outputs[j,i,0] = decoder_outputs[j,i,0] + x_offset[j]\n",
    "                decoder_outputs[j,i,1] = decoder_outputs[j,i,1] + y_offset[j]\n",
    "            \n",
    "                if (idx[j][0][0][0] in forecasted_trajectories):\n",
    "                    forecasted_trajectories[idx[j][0][0][0]].append(decoder_outputs[j,i,:].tolist())\n",
    "                else:\n",
    "                    forecasted_trajectories[idx[j][0][0][0]] = [decoder_outputs[j,i,:].tolist()]\n",
    "                \n",
    "    return(forecasted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = infer_absolute(test_loader, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>69420</td>\n",
       "      <td>[569.1348876953125, 2250.463134765625]</td>\n",
       "      <td>[569.5634765625, 2251.495361328125]</td>\n",
       "      <td>[569.4859008789062, 2252.1455078125]</td>\n",
       "      <td>[569.4866333007812, 2252.8544921875]</td>\n",
       "      <td>[569.4404907226562, 2253.501953125]</td>\n",
       "      <td>[569.4099731445312, 2254.143310546875]</td>\n",
       "      <td>[569.3798828125, 2254.77392578125]</td>\n",
       "      <td>[569.3560791015625, 2255.40380859375]</td>\n",
       "      <td>[569.33740234375, 2256.03662109375]</td>\n",
       "      <td>[569.3240966796875, 2256.676513671875]</td>\n",
       "      <td>...</td>\n",
       "      <td>[569.4024047851562, 2264.60791015625]</td>\n",
       "      <td>[569.4114990234375, 2265.3935546875]</td>\n",
       "      <td>[569.4180297851562, 2266.181640625]</td>\n",
       "      <td>[569.4215698242188, 2266.970458984375]</td>\n",
       "      <td>[569.4218139648438, 2267.7578125]</td>\n",
       "      <td>[569.4183349609375, 2268.5419921875]</td>\n",
       "      <td>[569.410888671875, 2269.321533203125]</td>\n",
       "      <td>[569.3991088867188, 2270.094970703125]</td>\n",
       "      <td>[569.3827514648438, 2270.8603515625]</td>\n",
       "      <td>[569.3614501953125, 2271.615966796875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42069</td>\n",
       "      <td>[3418.018798828125, 1889.5478515625]</td>\n",
       "      <td>[3419.313232421875, 1888.898193359375]</td>\n",
       "      <td>[3420.30078125, 1887.8602294921875]</td>\n",
       "      <td>[3420.860595703125, 1887.1685791015625]</td>\n",
       "      <td>[3421.375244140625, 1886.5740966796875]</td>\n",
       "      <td>[3422.04736328125, 1886.0665283203125]</td>\n",
       "      <td>[3422.81396484375, 1885.5904541015625]</td>\n",
       "      <td>[3423.579345703125, 1885.0941162109375]</td>\n",
       "      <td>[3424.294677734375, 1884.5634765625]</td>\n",
       "      <td>[3424.9521484375, 1884.0118408203125]</td>\n",
       "      <td>...</td>\n",
       "      <td>[3432.265869140625, 1879.7547607421875]</td>\n",
       "      <td>[3433.06298828125, 1879.542724609375]</td>\n",
       "      <td>[3433.85595703125, 1879.3375244140625]</td>\n",
       "      <td>[3434.631591796875, 1879.13330078125]</td>\n",
       "      <td>[3435.376708984375, 1878.924072265625]</td>\n",
       "      <td>[3436.0791015625, 1878.705078125]</td>\n",
       "      <td>[3436.72802734375, 1878.4720458984375]</td>\n",
       "      <td>[3437.314697265625, 1878.2225341796875]</td>\n",
       "      <td>[3437.83349609375, 1877.95556640625]</td>\n",
       "      <td>[3438.281494140625, 1877.671875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64209</td>\n",
       "      <td>[264.63311767578125, 3289.8251953125]</td>\n",
       "      <td>[264.613525390625, 3288.366943359375]</td>\n",
       "      <td>[264.6404724121094, 3287.393798828125]</td>\n",
       "      <td>[264.46502685546875, 3286.384765625]</td>\n",
       "      <td>[264.261474609375, 3285.3447265625]</td>\n",
       "      <td>[264.0484313964844, 3284.28369140625]</td>\n",
       "      <td>[263.8317565917969, 3283.202392578125]</td>\n",
       "      <td>[263.6130065917969, 3282.099609375]</td>\n",
       "      <td>[263.3922424316406, 3280.97412109375]</td>\n",
       "      <td>[263.1689147949219, 3279.8232421875]</td>\n",
       "      <td>...</td>\n",
       "      <td>[260.6233825683594, 3265.210693359375]</td>\n",
       "      <td>[260.4253845214844, 3263.788818359375]</td>\n",
       "      <td>[260.23236083984375, 3262.3837890625]</td>\n",
       "      <td>[260.03228759765625, 3260.998291015625]</td>\n",
       "      <td>[259.80621337890625, 3259.6298828125]</td>\n",
       "      <td>[259.5291748046875, 3258.2724609375]</td>\n",
       "      <td>[259.173828125, 3256.919921875]</td>\n",
       "      <td>[258.7164306640625, 3255.57470703125]</td>\n",
       "      <td>[258.1456604003906, 3254.255615234375]</td>\n",
       "      <td>[257.4710693359375, 3253.005615234375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13337</td>\n",
       "      <td>[2905.497314453125, 1491.284423828125]</td>\n",
       "      <td>[2904.52490234375, 1490.3553466796875]</td>\n",
       "      <td>[2903.96875, 1489.91064453125]</td>\n",
       "      <td>[2903.445068359375, 1489.322021484375]</td>\n",
       "      <td>[2902.91064453125, 1488.77978515625]</td>\n",
       "      <td>[2902.39013671875, 1488.248291015625]</td>\n",
       "      <td>[2901.873046875, 1487.7222900390625]</td>\n",
       "      <td>[2901.351318359375, 1487.19287109375]</td>\n",
       "      <td>[2900.81982421875, 1486.65625]</td>\n",
       "      <td>[2900.284423828125, 1486.114501953125]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2893.701416015625, 1479.583984375]</td>\n",
       "      <td>[2893.024169921875, 1478.9228515625]</td>\n",
       "      <td>[2892.332763671875, 1478.24951171875]</td>\n",
       "      <td>[2891.626220703125, 1477.5638427734375]</td>\n",
       "      <td>[2890.903564453125, 1476.8656005859375]</td>\n",
       "      <td>[2890.16259765625, 1476.1544189453125]</td>\n",
       "      <td>[2889.400390625, 1475.4295654296875]</td>\n",
       "      <td>[2888.613525390625, 1474.689697265625]</td>\n",
       "      <td>[2887.797607421875, 1473.9337158203125]</td>\n",
       "      <td>[2886.947998046875, 1473.159912109375]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0   \\\n",
       "69420  [569.1348876953125, 2250.463134765625]   \n",
       "42069    [3418.018798828125, 1889.5478515625]   \n",
       "64209   [264.63311767578125, 3289.8251953125]   \n",
       "13337  [2905.497314453125, 1491.284423828125]   \n",
       "\n",
       "                                           1   \\\n",
       "69420     [569.5634765625, 2251.495361328125]   \n",
       "42069  [3419.313232421875, 1888.898193359375]   \n",
       "64209   [264.613525390625, 3288.366943359375]   \n",
       "13337  [2904.52490234375, 1490.3553466796875]   \n",
       "\n",
       "                                           2   \\\n",
       "69420    [569.4859008789062, 2252.1455078125]   \n",
       "42069     [3420.30078125, 1887.8602294921875]   \n",
       "64209  [264.6404724121094, 3287.393798828125]   \n",
       "13337          [2903.96875, 1489.91064453125]   \n",
       "\n",
       "                                            3   \\\n",
       "69420     [569.4866333007812, 2252.8544921875]   \n",
       "42069  [3420.860595703125, 1887.1685791015625]   \n",
       "64209     [264.46502685546875, 3286.384765625]   \n",
       "13337   [2903.445068359375, 1489.322021484375]   \n",
       "\n",
       "                                            4   \\\n",
       "69420      [569.4404907226562, 2253.501953125]   \n",
       "42069  [3421.375244140625, 1886.5740966796875]   \n",
       "64209      [264.261474609375, 3285.3447265625]   \n",
       "13337     [2902.91064453125, 1488.77978515625]   \n",
       "\n",
       "                                           5   \\\n",
       "69420  [569.4099731445312, 2254.143310546875]   \n",
       "42069  [3422.04736328125, 1886.0665283203125]   \n",
       "64209   [264.0484313964844, 3284.28369140625]   \n",
       "13337   [2902.39013671875, 1488.248291015625]   \n",
       "\n",
       "                                           6   \\\n",
       "69420      [569.3798828125, 2254.77392578125]   \n",
       "42069  [3422.81396484375, 1885.5904541015625]   \n",
       "64209  [263.8317565917969, 3283.202392578125]   \n",
       "13337    [2901.873046875, 1487.7222900390625]   \n",
       "\n",
       "                                            7   \\\n",
       "69420    [569.3560791015625, 2255.40380859375]   \n",
       "42069  [3423.579345703125, 1885.0941162109375]   \n",
       "64209      [263.6130065917969, 3282.099609375]   \n",
       "13337    [2901.351318359375, 1487.19287109375]   \n",
       "\n",
       "                                          8   \\\n",
       "69420    [569.33740234375, 2256.03662109375]   \n",
       "42069   [3424.294677734375, 1884.5634765625]   \n",
       "64209  [263.3922424316406, 3280.97412109375]   \n",
       "13337         [2900.81982421875, 1486.65625]   \n",
       "\n",
       "                                           9   ...  \\\n",
       "69420  [569.3240966796875, 2256.676513671875]  ...   \n",
       "42069   [3424.9521484375, 1884.0118408203125]  ...   \n",
       "64209    [263.1689147949219, 3279.8232421875]  ...   \n",
       "13337  [2900.284423828125, 1486.114501953125]  ...   \n",
       "\n",
       "                                            20  \\\n",
       "69420    [569.4024047851562, 2264.60791015625]   \n",
       "42069  [3432.265869140625, 1879.7547607421875]   \n",
       "64209   [260.6233825683594, 3265.210693359375]   \n",
       "13337      [2893.701416015625, 1479.583984375]   \n",
       "\n",
       "                                           21  \\\n",
       "69420    [569.4114990234375, 2265.3935546875]   \n",
       "42069   [3433.06298828125, 1879.542724609375]   \n",
       "64209  [260.4253845214844, 3263.788818359375]   \n",
       "13337    [2893.024169921875, 1478.9228515625]   \n",
       "\n",
       "                                           22  \\\n",
       "69420     [569.4180297851562, 2266.181640625]   \n",
       "42069  [3433.85595703125, 1879.3375244140625]   \n",
       "64209   [260.23236083984375, 3262.3837890625]   \n",
       "13337   [2892.332763671875, 1478.24951171875]   \n",
       "\n",
       "                                            23  \\\n",
       "69420   [569.4215698242188, 2266.970458984375]   \n",
       "42069    [3434.631591796875, 1879.13330078125]   \n",
       "64209  [260.03228759765625, 3260.998291015625]   \n",
       "13337  [2891.626220703125, 1477.5638427734375]   \n",
       "\n",
       "                                            24  \\\n",
       "69420        [569.4218139648438, 2267.7578125]   \n",
       "42069   [3435.376708984375, 1878.924072265625]   \n",
       "64209    [259.80621337890625, 3259.6298828125]   \n",
       "13337  [2890.903564453125, 1476.8656005859375]   \n",
       "\n",
       "                                           25  \\\n",
       "69420    [569.4183349609375, 2268.5419921875]   \n",
       "42069       [3436.0791015625, 1878.705078125]   \n",
       "64209    [259.5291748046875, 3258.2724609375]   \n",
       "13337  [2890.16259765625, 1476.1544189453125]   \n",
       "\n",
       "                                           26  \\\n",
       "69420   [569.410888671875, 2269.321533203125]   \n",
       "42069  [3436.72802734375, 1878.4720458984375]   \n",
       "64209         [259.173828125, 3256.919921875]   \n",
       "13337    [2889.400390625, 1475.4295654296875]   \n",
       "\n",
       "                                            27  \\\n",
       "69420   [569.3991088867188, 2270.094970703125]   \n",
       "42069  [3437.314697265625, 1878.2225341796875]   \n",
       "64209    [258.7164306640625, 3255.57470703125]   \n",
       "13337   [2888.613525390625, 1474.689697265625]   \n",
       "\n",
       "                                            28  \\\n",
       "69420     [569.3827514648438, 2270.8603515625]   \n",
       "42069     [3437.83349609375, 1877.95556640625]   \n",
       "64209   [258.1456604003906, 3254.255615234375]   \n",
       "13337  [2887.797607421875, 1473.9337158203125]   \n",
       "\n",
       "                                           29  \n",
       "69420  [569.3614501953125, 2271.615966796875]  \n",
       "42069        [3438.281494140625, 1877.671875]  \n",
       "64209  [257.4710693359375, 3253.005615234375]  \n",
       "13337  [2886.947998046875, 1473.159912109375]  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(output, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    df[['v{}'.format((i*2)+1), 'v{}'.format((i*2)+2)]] = pd.DataFrame(df.get(i).tolist(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>69420</td>\n",
       "      <td>569.134888</td>\n",
       "      <td>2250.463135</td>\n",
       "      <td>569.563477</td>\n",
       "      <td>2251.495361</td>\n",
       "      <td>569.485901</td>\n",
       "      <td>2252.145508</td>\n",
       "      <td>569.486633</td>\n",
       "      <td>2252.854492</td>\n",
       "      <td>569.440491</td>\n",
       "      <td>2253.501953</td>\n",
       "      <td>...</td>\n",
       "      <td>569.418335</td>\n",
       "      <td>2268.541992</td>\n",
       "      <td>569.410889</td>\n",
       "      <td>2269.321533</td>\n",
       "      <td>569.399109</td>\n",
       "      <td>2270.094971</td>\n",
       "      <td>569.382751</td>\n",
       "      <td>2270.860352</td>\n",
       "      <td>569.361450</td>\n",
       "      <td>2271.615967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42069</td>\n",
       "      <td>3418.018799</td>\n",
       "      <td>1889.547852</td>\n",
       "      <td>3419.313232</td>\n",
       "      <td>1888.898193</td>\n",
       "      <td>3420.300781</td>\n",
       "      <td>1887.860229</td>\n",
       "      <td>3420.860596</td>\n",
       "      <td>1887.168579</td>\n",
       "      <td>3421.375244</td>\n",
       "      <td>1886.574097</td>\n",
       "      <td>...</td>\n",
       "      <td>3436.079102</td>\n",
       "      <td>1878.705078</td>\n",
       "      <td>3436.728027</td>\n",
       "      <td>1878.472046</td>\n",
       "      <td>3437.314697</td>\n",
       "      <td>1878.222534</td>\n",
       "      <td>3437.833496</td>\n",
       "      <td>1877.955566</td>\n",
       "      <td>3438.281494</td>\n",
       "      <td>1877.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64209</td>\n",
       "      <td>264.633118</td>\n",
       "      <td>3289.825195</td>\n",
       "      <td>264.613525</td>\n",
       "      <td>3288.366943</td>\n",
       "      <td>264.640472</td>\n",
       "      <td>3287.393799</td>\n",
       "      <td>264.465027</td>\n",
       "      <td>3286.384766</td>\n",
       "      <td>264.261475</td>\n",
       "      <td>3285.344727</td>\n",
       "      <td>...</td>\n",
       "      <td>259.529175</td>\n",
       "      <td>3258.272461</td>\n",
       "      <td>259.173828</td>\n",
       "      <td>3256.919922</td>\n",
       "      <td>258.716431</td>\n",
       "      <td>3255.574707</td>\n",
       "      <td>258.145660</td>\n",
       "      <td>3254.255615</td>\n",
       "      <td>257.471069</td>\n",
       "      <td>3253.005615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13337</td>\n",
       "      <td>2905.497314</td>\n",
       "      <td>1491.284424</td>\n",
       "      <td>2904.524902</td>\n",
       "      <td>1490.355347</td>\n",
       "      <td>2903.968750</td>\n",
       "      <td>1489.910645</td>\n",
       "      <td>2903.445068</td>\n",
       "      <td>1489.322021</td>\n",
       "      <td>2902.910645</td>\n",
       "      <td>1488.779785</td>\n",
       "      <td>...</td>\n",
       "      <td>2890.162598</td>\n",
       "      <td>1476.154419</td>\n",
       "      <td>2889.400391</td>\n",
       "      <td>1475.429565</td>\n",
       "      <td>2888.613525</td>\n",
       "      <td>1474.689697</td>\n",
       "      <td>2887.797607</td>\n",
       "      <td>1473.933716</td>\n",
       "      <td>2886.947998</td>\n",
       "      <td>1473.159912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                v1           v2           v3           v4           v5  \\\n",
       "ID                                                                       \n",
       "69420   569.134888  2250.463135   569.563477  2251.495361   569.485901   \n",
       "42069  3418.018799  1889.547852  3419.313232  1888.898193  3420.300781   \n",
       "64209   264.633118  3289.825195   264.613525  3288.366943   264.640472   \n",
       "13337  2905.497314  1491.284424  2904.524902  1490.355347  2903.968750   \n",
       "\n",
       "                v6           v7           v8           v9          v10  ...  \\\n",
       "ID                                                                      ...   \n",
       "69420  2252.145508   569.486633  2252.854492   569.440491  2253.501953  ...   \n",
       "42069  1887.860229  3420.860596  1887.168579  3421.375244  1886.574097  ...   \n",
       "64209  3287.393799   264.465027  3286.384766   264.261475  3285.344727  ...   \n",
       "13337  1489.910645  2903.445068  1489.322021  2902.910645  1488.779785  ...   \n",
       "\n",
       "               v51          v52          v53          v54          v55  \\\n",
       "ID                                                                       \n",
       "69420   569.418335  2268.541992   569.410889  2269.321533   569.399109   \n",
       "42069  3436.079102  1878.705078  3436.728027  1878.472046  3437.314697   \n",
       "64209   259.529175  3258.272461   259.173828  3256.919922   258.716431   \n",
       "13337  2890.162598  1476.154419  2889.400391  1475.429565  2888.613525   \n",
       "\n",
       "               v56          v57          v58          v59          v60  \n",
       "ID                                                                      \n",
       "69420  2270.094971   569.382751  2270.860352   569.361450  2271.615967  \n",
       "42069  1878.222534  3437.833496  1877.955566  3438.281494  1877.671875  \n",
       "64209  3255.574707   258.145660  3254.255615   257.471069  3253.005615  \n",
       "13337  1474.689697  2887.797607  1473.933716  2886.947998  1473.159912  \n",
       "\n",
       "[4 rows x 60 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dropped_cols = list(np.arange(30))\n",
    "df2 = df.drop(dropped_cols, axis=1)\n",
    "df2.index.name = 'ID'\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"outputs1ep_train.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
