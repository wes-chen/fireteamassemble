{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy\n",
    "import pickle\n",
    "from glob import glob\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "test_path = './new_val_in/new_val_in'\n",
    "subset_test_path = './new_train/train_subset'\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "test_dataset = ArgoverseDataset(data_path=test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def train_agents_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    out = numpy.concatenate([numpy.dstack([scene['p_out'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def train_all_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][['dummy' not in word for word in scene['track_id'][:,0,0]],:,:]]) for scene in batch])\n",
    "    out = numpy.concatenate([numpy.dstack([scene['p_out'][['dummy' not in word for word in scene['track_id'][:,0,0]],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    out = torch.Tensor(out)\n",
    "    return [inp, out]\n",
    "    \n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = numpy.concatenate([numpy.dstack([scene['p_in'][scene['track_id'][:,0,0]==scene['agent_id'],:,:]]) for scene in batch])\n",
    "    inp = torch.Tensor(inp)\n",
    "    idx = [numpy.dstack([scene['scene_idx']]) for scene in batch]\n",
    "    return inp, idx\n",
    "    \n",
    "train_agent_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_agents_collate, num_workers=0)\n",
    "\n",
    "train_all_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=train_all_collate, num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz, shuffle = True, collate_fn=test_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size = 2,\n",
    "                 embedding_size = 8,\n",
    "                 hidden_size = 16):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        dropnum = 0.35\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.drop1 = nn.Dropout(dropnum)\n",
    "        self.drop2 = nn.BatchNorm1d(embedding_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        embedded = F.relu(self.linear(x))\n",
    "        embedded = self.drop2(embedded)\n",
    "        hidden = self.lstm(embedded, hidden)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"Decoder Network.\"\"\"\n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    def __init__(self, embedding_size=8, hidden_size=16, output_size=2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.linear1 = nn.Linear(output_size, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = F.relu(self.linear1(x))\n",
    "        hidden = self.lstm(embedded, hidden)\n",
    "        output = self.linear2(hidden[0])\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def train(encoder, decoder, device, train_loader, encoder_optimizer, decoder_optimizer, epoch, log_interval=10000):    \n",
    "    \"\"\"referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\"\"\"\n",
    "    \n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        \n",
    "        inp, out = sample_batch\n",
    "#         print(inp.shape)\n",
    "        # preprocessing more ????\n",
    "#         inp = inp[:,0,:,:]\n",
    "#         out = out[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(inp.shape[0]):\n",
    "            x_offset.append(inp[i][0][0].detach().clone())\n",
    "            y_offset.append(inp[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(inp.shape[0]):\n",
    "            for i in range(inp.shape[1]):\n",
    "                inp[j][i][0] = inp[j][i][0] - x_offset[j]\n",
    "                inp[j][i][1] = inp[j][i][1] - y_offset[j]\n",
    "\n",
    "        #outoput whatever\n",
    "        for j in range(out.shape[0]):\n",
    "            for i in range(out.shape[1]):\n",
    "                out[j][i][0] = out[j][i][0] - x_offset[j]\n",
    "                out[j][i][1] = out[j][i][1] - y_offset[j]\n",
    "        \n",
    "        _input, target = inp.to(device), out.to(device)\n",
    "        \n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        #encoder \n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        output_length = target.shape[1]\n",
    "        feature_len = _input.shape[2]\n",
    "        input_shape = _input.shape[2]\n",
    "        \n",
    "        encoder_hidden = (torch.zeros(batch_size, encoder.module.hidden_size).to(device), \n",
    "                          torch.zeros(batch_size, encoder.module.hidden_size).to(device))\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "        print(\"DECODER INPUT\", decoder_input.shape)\n",
    "        print(\"DECODER HIDDEN\", decoder_hidden[0].shape)\n",
    "\n",
    "        decoder_outputs = torch.zeros(target.shape).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Update loss\n",
    "            loss += torch.sqrt(criterion(decoder_output[:, :2], target[:, di, :2]))\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        # Get average loss for pred_len\n",
    "        loss = loss / 30\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "#         file1 = open(\"loss_steps.txt\", \"a\")  # append mode\n",
    "#         file1.write(str(loss.item()) + \",\")\n",
    "#         file1.close()\n",
    "        \n",
    "#       output = model(data)\n",
    "#         loss = MSELoss(output, target)\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9a45284a4a4adea1fadc65616daf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER INPUT torch.Size([49, 2])\n",
      "DECODER HIDDEN torch.Size([49, 16])\n",
      "ENCODER INPUT torch.Size([37, 2])\n",
      "DECODER HIDDEN torch.Size([37, 16])\n",
      "ENCODER INPUT torch.Size([29, 2])\n",
      "DECODER HIDDEN torch.Size([29, 16])\n",
      "ENCODER INPUT torch.Size([36, 2])\n",
      "DECODER HIDDEN torch.Size([36, 16])\n",
      "ENCODER INPUT torch.Size([26, 2])\n",
      "DECODER HIDDEN torch.Size([26, 16])\n",
      "ENCODER INPUT torch.Size([34, 2])\n",
      "DECODER HIDDEN torch.Size([34, 16])\n",
      "ENCODER INPUT torch.Size([46, 2])\n",
      "DECODER HIDDEN torch.Size([46, 16])\n",
      "ENCODER INPUT torch.Size([42, 2])\n",
      "DECODER HIDDEN torch.Size([42, 16])\n",
      "ENCODER INPUT torch.Size([45, 2])\n",
      "DECODER HIDDEN torch.Size([45, 16])\n",
      "ENCODER INPUT torch.Size([38, 2])\n",
      "DECODER HIDDEN torch.Size([38, 16])\n",
      "ENCODER INPUT torch.Size([31, 2])\n",
      "DECODER HIDDEN torch.Size([31, 16])\n",
      "ENCODER INPUT torch.Size([34, 2])\n",
      "DECODER HIDDEN torch.Size([34, 16])\n",
      "ENCODER INPUT torch.Size([59, 2])\n",
      "DECODER HIDDEN torch.Size([59, 16])\n",
      "ENCODER INPUT torch.Size([26, 2])\n",
      "DECODER HIDDEN torch.Size([26, 16])\n",
      "ENCODER INPUT torch.Size([39, 2])\n",
      "DECODER HIDDEN torch.Size([39, 16])\n",
      "ENCODER INPUT torch.Size([51, 2])\n",
      "DECODER HIDDEN torch.Size([51, 16])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3667f8849911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_all_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#         train(encoder, decoder, device, train_agent_loader, encoder_optimizer, decoder_optimizer, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         predict(model, device, test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c97b410e7075>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, device, train_loader, encoder_optimizer, decoder_optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "encoder = EncoderRNN(input_size=2)\n",
    "decoder = DecoderRNN(output_size=2)\n",
    "\n",
    "encoder = nn.DataParallel(encoder)\n",
    "decoder = nn.DataParallel(decoder)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "num_epoch = 6\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    train(encoder, decoder, device, train_all_loader, encoder_optimizer, decoder_optimizer, epoch)\n",
    "#         train(encoder, decoder, device, train_agent_loader, encoder_optimizer, decoder_optimizer, epoch)\n",
    "#         predict(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_absolute(\n",
    "        test_loader: torch.utils.data.DataLoader,\n",
    "        encoder: EncoderRNN,\n",
    "        decoder: DecoderRNN,\n",
    "#         start_idx: int,\n",
    "#         forecasted_save_dir: str,\n",
    "#         model_utils: ModelUtils,\n",
    "):\n",
    "    \"\"\"Infer function for non-map LSTM baselines and save the forecasted trajectories.\n",
    "    \n",
    "    referenced from official Argoverse forecasting code: https://github.com/jagjeet-singh/argoverse-forecasting\n",
    "    \n",
    "    Args:\n",
    "        test_loader: DataLoader for the test set\n",
    "        encoder: Encoder network instance\n",
    "        decoder: Decoder network instance\n",
    "        start_idx: start index for the current joblib batch\n",
    "        forecasted_save_dir: Directory where forecasted trajectories are to be saved\n",
    "        model_utils: ModelUtils instance\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    forecasted_trajectories = {}\n",
    "\n",
    "    for i, (_input, idx) in enumerate(test_loader):\n",
    "        \n",
    "#         _input = _input[:,0,:,:]\n",
    "        \n",
    "        #inp - inp[0] for all in whaetver\n",
    "        x_offset = []\n",
    "        y_offset = []\n",
    "        for i in range(_input.shape[0]):\n",
    "            x_offset.append(_input[i][0][0].detach().clone())\n",
    "            y_offset.append(_input[i][0][1].detach().clone())\n",
    "    \n",
    "        for j in range(_input.shape[0]):\n",
    "            for i in range(_input.shape[1]):\n",
    "                _input[j][i][0] = _input[j][i][0] - x_offset[j]\n",
    "                _input[j][i][1] = _input[j][i][1] - y_offset[j]\n",
    "\n",
    "        _input = _input.to(device)\n",
    "\n",
    "        # Set to eval mode\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = _input.shape[0]\n",
    "        input_length = _input.shape[1]\n",
    "        input_shape = _input.shape[2]\n",
    "\n",
    "        # Initialize encoder hidden state\n",
    "        encoder_hidden = (torch.zeros(batch_size, encoder.module.hidden_size).to(device), \n",
    "                          torch.zeros(batch_size, encoder.module.hidden_size).to(device))\n",
    "       \n",
    "        # Encode observed trajectory\n",
    "        for ei in range(input_length):\n",
    "            encoder_input = _input[:, ei, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Initialize decoder hidden state as encoder hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_outputs = torch.zeros(\n",
    "            (batch_size, 30, 2)).to(device)\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for di in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input,\n",
    "                                                     decoder_hidden)\n",
    "            decoder_outputs[:, di, :] = decoder_output\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        for i in range(30):\n",
    "            for j in range(batch_size):\n",
    "                decoder_outputs[j,i,0] = decoder_outputs[j,i,0] + x_offset[j]\n",
    "                decoder_outputs[j,i,1] = decoder_outputs[j,i,1] + y_offset[j]\n",
    "            \n",
    "                if (idx[j][0][0][0] in forecasted_trajectories):\n",
    "                    forecasted_trajectories[idx[j][0][0][0]].append(decoder_outputs[j,i,:].tolist())\n",
    "                else:\n",
    "                    forecasted_trajectories[idx[j][0][0][0]] = [decoder_outputs[j,i,:].tolist()]\n",
    "                \n",
    "    return(forecasted_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = infer_absolute(test_loader, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(output, orient='index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    df[['v{}'.format((i*2)+1), 'v{}'.format((i*2)+2)]] = pd.DataFrame(df.get(i).tolist(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dropped_cols = list(np.arange(30))\n",
    "df2 = df.drop(dropped_cols, axis=1)\n",
    "df2.index.name = 'ID'\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"outputs6epb4all_batchnormEncoder.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
